import google.generativeai as genai
from fastapi import FastAPI, UploadFile, File, Form
from fastapi.responses import FileResponse, JSONResponse
from typing import Optional
import fitz
import numpy as np
import spacy
import pandas as pd
import streamlit as st # Keep streamlit import, some functions might still use it internally, but remove UI elements
from collections import Counter
from io import BytesIO
from textstat import textstat
from reportlab.platypus.flowables import PageBreak
import requests
import tarfile
import io
import re
import json
import os
import pytesseract
from spellchecker import SpellChecker
from textblob import TextBlob
from reportlab.pdfgen import canvas
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageTemplate, Frame, Image, Table, TableStyle
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.platypus import Image as RLImage
from reportlab.lib.enums import TA_JUSTIFY
from reportlab.lib.pagesizes import letter
from reportlab.lib.utils import ImageReader
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.pdfbase import pdfmetrics
from reportlab.lib import colors
from reportlab.lib.units import inch
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt
import statsmodels.api as sm
from spellchecker import SpellChecker
import re
from PIL import Image as PILImage
from PIL import Image, ImageFilter, ImageOps, ImageEnhance
from fastapi.responses import JSONResponse
import shutil
import base64  # Import base64 for encoding PDF

app = FastAPI()

# Cargar las palabras clave y consejos desde los archivos JSON
def load_indicators(filepath="indicators.json"):
    with open(filepath, "r", encoding="utf-8") as file:
        return json.load(file)
def load_advice(filepath="advice.json"):
    with open(filepath, "r", encoding="utf-8") as file:
        return json.load(file)
def load_profile_examples():
    with open("profile.json", "r") as f:
        return json.load(f)

# Cargar indicadores y consejos al inicio del script
indicators = load_indicators()
advice = load_advice()
profile_examples = load_profile_examples()

# Uso del c√≥digo
background_path = "Fondo reporte.png"
portada_path= "Portada Analizador.png"

# Asegurar que las dependencias de NLTK est√©n descargadas
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download("wordnet")

def preprocess_image(image):
    """
    Preprocesa una imagen antes de aplicar OCR.
    :param image: Imagen a preprocesar.
    :return: Imagen preprocesada.
    """
    # Convertir la imagen a escala de grises
    image = image.convert("L")

    # Mejorar el contraste
    enhancer = ImageEnhance.Contrast(image)
    image = enhancer.enhance(2.0)

    # Aplicar umbral para binarizaci√≥n
    image = ImageOps.autocontrast(image)

    return image

def extract_text_with_ocr(pdf_path):
    """
    Extrae texto de un PDF utilizando PyMuPDF y OCR con preprocesamiento optimizado.
    :param pdf_path: Ruta del archivo PDF.
    :return: Texto extra√≠do del PDF.
    """
    extracted_text = []

    with fitz.open(pdf_path) as doc:
        for page in doc:
            # üìå **1Ô∏è‚É£ Intentar extraer texto directamente**
            page_text = page.get_text("text").strip()

            if not page_text:  # Si no hay texto, usar OCR
                pix = page.get_pixmap(dpi=300)  # Aumentar DPI para mejorar OCR
                img = Image.open(io.BytesIO(pix.tobytes(output="png")))

                # üìå **2Ô∏è‚É£ Preprocesamiento de imagen**
                img = img.convert("L")  # Convertir a escala de grises
                img = img.filter(ImageFilter.MedianFilter())  # Reducir ruido
                enhancer = ImageEnhance.Contrast(img)
                img = enhancer.enhance(2)  # Aumentar contraste

                # üìå **3Ô∏è‚É£ Aplicar OCR**
                page_text = pytesseract.image_to_string(img, config="--psm 3").strip()

            extracted_text.append(page_text)

    return "\n".join(extracted_text)

def extract_cleaned_lines(text):
    if isinstance(text, list):
        text = "\n".join(text)  # Convierte la lista en un texto √∫nico antes de dividirlo

    lines = text.split("\n")  # Ahora estamos seguros de que text es una cadena
    cleaned_lines = []

    for line in lines:
        line = line.strip()

        # üìå **1Ô∏è‚É£ Filtrar l√≠neas vac√≠as y no imprimibles**
        if not line or not any(char.isalnum() for char in line):
            continue  # Ignorar l√≠neas sin caracteres alfanum√©ricos

        # üìå **2Ô∏è‚É£ Remover l√≠neas con solo n√∫meros (ejemplo: n√∫meros de p√°gina)**
        if re.fullmatch(r"\d+", line):
            continue

        # üìå **3Ô∏è‚É£ Ignorar l√≠neas con muy pocos caracteres (posibles errores OCR)**
        if len(line) < 3:
            continue

        cleaned_lines.append(line)

    return cleaned_lines

def calculate_all_indicators(lines, position_indicators):
    """
    Calcula los porcentajes de todos los indicadores para un cargo.
    :param lines: Lista de l√≠neas de la secci√≥n "EXPERIENCIA EN ANEIAP".
    :param position_indicators: Diccionario de indicadores y palabras clave del cargo.
    :return: Diccionario con los porcentajes por indicador.
    """
    total_lines = len(lines)
    if total_lines == 0:
        return {indicator: 0 for indicator in position_indicators}  # Evitar divisi√≥n por cero

    indicator_results = {}
    for indicator, keywords in position_indicators.items():
        relevant_lines = sum(
            any(keyword.lower() in line.lower() for keyword in keywords) for line in lines
        )
        indicator_results[indicator] = (relevant_lines / total_lines) * 100  # C√°lculo del porcentaje
    return indicator_results

def calculate_indicators_for_report(lines, position_indicators):
    """
    Calcula los porcentajes de relevancia de indicadores para el reporte.
    :param lines: Lista de l√≠neas de la secci√≥n "EXPERIENCIA EN ANEIAP".
    :param position_indicators: Diccionario de indicadores y palabras clave del cargo.
    :return: Diccionario con los porcentajes por indicador y detalles de l√≠neas relevantes.
    """
    total_lines = len(lines)
    if total_lines == 0:
        return {indicator: {"percentage": 0, "relevant_lines": 0} for indicator in position_indicators}

    indicator_results = {}
    for indicator, keywords in position_indicators.items():
        relevant_lines = sum(
            any(keyword.lower() in line.lower() for keyword in keywords) for line in lines
        )
        percentage = (relevant_lines / total_lines) * 100
        indicator_results[indicator] = {"percentage": percentage, "relevant_lines": relevant_lines}

    return indicator_results

# Funci√≥n para calcular la similitud usando TF-IDF y similitud de coseno
def clean_text(text):
    """Limpia el texto eliminando caracteres especiales y espacios extra."""

    if not isinstance(text, str):  # Si no es una cadena de texto, manejar el error
        print(f"‚ö†Ô∏è Error en clean_text: Se esperaba str, pero se recibi√≥ {type(text)} -> {text}")
        return ""  # Evita que falle devolviendo una cadena vac√≠a

    text = re.sub(r"[^\w\s]", "", text)  # Elimina puntuaci√≥n
    text = re.sub(r"\s+", " ", text).strip().lower()  # Normaliza espacios y min√∫sculas
    return text

def calculate_similarity(text1, text2):
    """Calcula la similitud entre dos textos usando TF-IDF y similitud de coseno."""

    if not isinstance(text1, str) or not isinstance(text2, str):
        print(f"‚ö†Ô∏è Error en calculate_similarity: text1 ({type(text1)}) = {text1}, text2 ({type(text2)}) = {text2}")
        return 0  # Evita errores si los valores son incorrectos

    text1, text2 = clean_text(text1), clean_text(text2)

    if not text1 or not text2:  # Si despu√©s de limpiar los textos est√°n vac√≠os
        print(f"‚ö†Ô∏è Textos vac√≠os despu√©s de limpieza: text1='{text1}', text2='{text2}'")
        return 0

    try:
        vectorizer = TfidfVectorizer(ngram_range=(1,2), stop_words="english")
        tfidf_matrix = vectorizer.fit_transform([text1, text2])
        similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]
        return round(similarity * 100, 2)
    except Exception as e:
        print(f"‚ö†Ô∏è Error en calculate_similarity: {e}")
        return 0

def calculate_presence(texts, keywords):
    """
    Calcula el porcentaje de palabras clave presentes en los textos.
    :param texts: Lista de textos (e.g., detalles).
    :param keywords: Lista de palabras clave a buscar.
    :return: Porcentaje de coincidencia.
    """
    if not texts or not keywords:
        return 0  # Evitar divisi√≥n por cero

    keywords = set(map(str.lower, keywords))  # Convertir palabras clave a min√∫sculas
    matches = 0

    for text in texts:
        words = set(re.findall(r"\b\w+\b", text.lower()))  # Extraer palabras √∫nicas en min√∫sculas
        matches += sum(1 for keyword in keywords if keyword in words)

    return round((matches / len(keywords)) * 100, 2)  # Redondear a 2 decimales


def draw_full_page_cover(canvas, portada_path, candidate_name, position,chapter):
    """
    Dibuja la portada con una imagen a p√°gina completa y el t√≠tulo del reporte completamente centrado.
    :param canvas: Lienzo de ReportLab.
    :param portada_path: Ruta de la imagen de la portada.
    :param candidate_name: Nombre del candidato.
    :param position: Cargo al que aspira.
    :param chapter: Cap√≠tulo del Candidato
    """
    # üìå Obtener el tama√±o de la p√°gina (Carta)
    page_width, page_height = letter

    # üìå Cargar la imagen de la portada
    img = ImageReader(portada_path)
    img_width, img_height = img.getSize()

    # üìå Ajustar la imagen proporcionalmente para que llene la p√°gina
    scale_factor = max(page_width / img_width, page_height / img_height)
    new_width = img_width * scale_factor
    new_height = img_height * scale_factor

    # üìå Centrar la imagen en la p√°gina
    x_offset = (page_width - new_width) / 2
    y_offset = (page_height - new_height) / 2

    # üìå Dibujar la imagen de portada en toda la p√°gina
    canvas.drawImage(portada_path, x_offset, y_offset, width=new_width, height=new_height)

    # üìå **AGREGAR EL T√çTULO DEL REPORTE EN EL CENTRO**
    title_style = ParagraphStyle(name="Title", fontName="CenturyGothicBold", fontSize=48, textColor=colors.black, alignment=1,)

    title_text = f"REPORTE DE AN√ÅLISIS\n{candidate_name.upper()}\nCARGO: {position.upper()}\nCAP√çTULO:{chapter.upper()}"

    # üìå Configurar fuente y color del texto
    canvas.setFont("CenturyGothicBold", 36)
    canvas.setFillColor(colors.black)

    # üìå Medir el ancho y alto del texto
    text_width = max(canvas.stringWidth(line, "CenturyGothicBold", 36) for line in title_text.split("\n"))
    text_height = 36 * len(title_text.split("\n"))  # Multiplicamos por el n√∫mero de l√≠neas

    # üìå Centrar el texto
    text_x = (page_width - text_width) / 2
    text_y = (page_height - text_height) / 2  # Ajuste para centrar verticalmente

    # üìå Dibujar cada l√≠nea del t√≠tulo centrado
    for i, line in enumerate(title_text.split("\n")):
        line_width = canvas.stringWidth(line, "CenturyGothicBold", 36)
        line_x = (page_width - line_width) / 2
        canvas.drawString(line_x, text_y - (i * 30), line)  # Espaciado entre l√≠neas


def add_background(canvas, background_path):
    """
    Dibuja una imagen de fondo en cada p√°gina del PDF.
    :param canvas: Lienzo de ReportLab.
    :param background_path: Ruta a la imagen de fondo.
    """
    canvas.saveState()
    canvas.drawImage(background_path, 0, 0, width=letter[0], height=letter[1])
    canvas.restoreState()

# FUNCIONES PARA PRIMARY
def count_matching_keywords(text, keywords):
    """
    Cuenta cu√°ntas palabras clave aparecen en un texto y calcula su peso relativo.
    :param text: Texto de la secci√≥n "Perfil".
    :param keyword_sets: Diccionario con listas de palabras clave agrupadas por categor√≠a.
    :return: Total de palabras en el perfil y porcentaje de coincidencia con palabras clave.
    """
    words = re.findall(r"\b\w+\b", text.lower())  # Tokeniza sin usar NLTK
    total_words = len(words)

    # Crear un contador de palabras en el texto
    word_freq = Counter(words)

    # Contar coincidencias con palabras clave
    keyword_count = sum(word_freq[word] for kw_set in keywords.values() for word in kw_set if word in word_freq)

    # Evitar divisi√≥n por cero
    match_percentage = (keyword_count / total_words) * 100 if total_words > 0 else 0

    return total_words, keyword_count, match_percentage

def extract_profile_section_with_ocr(pdf_path):
    """
    Extrae la secci√≥n 'Perfil' de un archivo PDF con soporte de OCR.
    :param pdf_path: Ruta del archivo PDF.
    :return: Texto de la secci√≥n 'Perfil'.
    """
    text = extract_text_with_ocr(pdf_path)

    if not text or len(text.strip()) == 0:
        print("‚ö†Ô∏è No se pudo extraer texto del PDF.")
        return ""

    # Palabras clave para identificar el inicio y fin de la secci√≥n
    start_keyword = "Perfil"
    end_keywords = [
        "Asistencia a eventos",
        "Actualizaci√≥n profesional",
    ]

    # Buscar la palabra clave de inicio
    start_idx = text.lower().find(start_keyword.lower())
    if start_idx == -1:
        print("‚ö†Ô∏è No se encontr√≥ la secci√≥n 'Perfil'.")
        return ""

    # Encontrar el √≠ndice m√°s cercano de las palabras clave de fin
    end_idx = len(text)
    for keyword in end_keywords:
        idx = text.lower().find(keyword.lower(), start_idx)
        if idx != -1:
            end_idx = min(end_idx, idx)

    # Extraer la secci√≥n entre inicio y fin
    candidate_profile_text = text[start_idx:end_idx].strip()

    # Depuraci√≥n del texto extra√≠do
    cleaned_profile_text = re.sub(r"[^\w\s.,;:()\-]", "", candidate_profile_text)  # Mantiene par√©ntesis y guiones
    cleaned_profile_text = re.sub(r"\s+", " ", cleaned_profile_text)  # Normaliza espacios

    return cleaned_profile_text

def extract_experience_section_with_ocr(pdf_path):
    """
    Extrae la secci√≥n 'EXPERIENCIA EN ANEIAP' de un archivo PDF con soporte de OCR.
    :param pdf_path: Ruta del archivo PDF.
    :return: Texto de la secci√≥n 'EXPERIENCIA EN ANEIAP'.
    """
    text = extract_text_with_ocr(pdf_path)

    # Palabras clave para identificar inicio y fin de la secci√≥n
    start_keyword = "EXPERIENCIA EN ANEIAP"
    end_keywords = [
        "EVENTOS ORGANIZADOS",
        "Reconocimientos individuales",
        "Reconocimientos grupales",
        "Reconocimientos",
    ]

    # Encontrar √≠ndice de inicio
    start_idx = text.lower().find(start_keyword.lower())
    if start_idx == -1:
        return None  # No se encontr√≥ la secci√≥n

    # Encontrar √≠ndice m√°s cercano de fin basado en palabras clave
    end_idx = len(text)  # Por defecto, tomar hasta el final
    for keyword in end_keywords:
        idx = text.lower().find(keyword.lower(), start_idx)
        if idx != -1:
            end_idx = min(end_idx, idx)

    # Extraer la secci√≥n entre inicio y fin
    experience_text = text[start_idx:end_idx].strip()

    # Filtrar y limpiar texto
    exclude_lines = [
        "a nivel capitular",
        "a nivel nacional",
        "a nivel seccional",
        "reconocimientos individuales",
        "reconocimientos grupales",
        "trabajo capitular",
        "trabajo nacional",
        "nacional 2024",
        "nacional 20212023",
    ]
    experience_lines = experience_text.split("\n")
    cleaned_lines = []
    for line in experience_lines:
        line = line.strip()
        line = re.sub(r"[^\w\s]", "", line)  # Eliminar caracteres no alfanum√©ricos excepto espacios
        normalized_line = re.sub(r"\s+", " ", line).lower()  # Normalizar espacios y convertir a min√∫sculas
        if (
            normalized_line
            and normalized_line not in exclude_lines
            and normalized_line != start_keyword.lower()
            and normalized_line not in [kw.lower() for kw in end_keywords]
        ):
            cleaned_lines.append(line)

    return "\n".join(cleaned_lines)

    # Debugging: Imprime l√≠neas procesadas
    print("L√≠neas procesadas:")
    for line in cleaned_lines:
        print(f"- {line}")

    return "\n".join(cleaned_lines)

def extract_event_section_with_ocr(pdf_path):
    """
    Extrae la secci√≥n 'EVENTOS ORGANIZADOS' de un archivo PDF con OCR,
    asegurando que los √≠tems sean correctamente identificados.
    """
    text = extract_text_with_ocr(pdf_path)
    if not text:
        return []  # Retorna lista vac√≠a si no hay contenido

    text = extract_text_with_ocr(pdf_path)

    # Palabras clave para identificar inicio y fin de la secci√≥n
    start_keyword = "EVENTOS ORGANIZADOS"
    end_keywords = [
        "EXPERIENCIA LABORAL",
        "FIRMA",
    ]

    # Encontrar √≠ndice de inicio
    start_idx = text.lower().find(start_keyword.lower())
    if start_idx == -1:
        return None  # No se encontr√≥ la secci√≥n

    # Encontrar √≠ndice m√°s cercano de fin basado en palabras clave
    end_idx = len(text)  # Por defecto, tomar hasta el final
    for keyword in end_keywords:
        idx = text.lower().find(keyword.lower(), start_idx)
        if idx != -1:
            end_idx = min(end_idx, idx)

    # Extraer la secci√≥n entre inicio y fin
    org_text = text[start_idx:end_idx].strip()

    # Filtrar y limpiar texto
    exclude_lines = [
        "a nivel capitular",
        "a nivel nacional",
        "a nivel seccional",
        "reconocimientos individuales",
        "reconocimientos grupales",
        "trabajo capitular",
        "trabajo nacional",
        "nacional 2024",
        "nacional 20212023",
    ]
    org_lines = org_text.split("\n")
    cleaned_lines = []
    for line in org_lines:
        line = line.strip()
        line = re.sub(r"[^\w\s]", "", line)  # Eliminar caracteres no alfanum√©ricos excepto espacios
        normalized_line = re.sub(r"\s+", " ", line).lower()  # Normalizar espacios y convertir a min√∫sculas
        if (
            normalized_line
            and normalized_line not in exclude_lines
            and normalized_line != start_keyword.lower()
            and normalized_line not in [kw.lower() for kw in end_keywords]
        ):
            cleaned_lines.append(line)

    return "\n".join(cleaned_lines)

    # Debugging: Imprime l√≠neas procesadas
    print("L√≠neas procesadas:")
    for line in cleaned_lines:
        print(f"- {line}")

    return "\n".join(cleaned_lines)

def evaluate_cv_presentation(pdf_path):
    """
    Eval√∫a la presentaci√≥n de la hoja de vida en t√©rminos de redacci√≥n, ortograf√≠a,
    coherencia b√°sica, y claridad.
    :param pdf_path: Ruta del archivo PDF.
    :return: Texto limpio y an√°lisis detallado de la presentaci√≥n.
    """
    # Extraer texto completo de la hoja de vida
    resume_text = extract_text_with_ocr(pdf_path)

    if not resume_text:
        return None, "No se pudo extraer el texto de la hoja de vida."

    # Limpiar y filtrar texto
    pres_cleaned_lines = []
    lines = resume_text.split("\n")
    for line in lines:
        line = line.strip()
        line = re.sub(r"[^\w\s.,;:!?-]", "", line)  # Eliminar caracteres no alfanum√©ricos excepto signos b√°sicos
        line = re.sub(r"\s+", " ", line)  # Normalizar espacios
        if line:
            pres_cleaned_lines.append(line)

    # Evaluaci√≥n de calidad de presentaci√≥n
    total_lines = len(pres_cleaned_lines)
    if total_lines == 0:
        return None, "El documento est√° vac√≠o o no contiene texto procesable."

    return "\n".join(pres_cleaned_lines)

def extract_attendance_section_with_ocr(pdf_path):
    """
    Extrae la secci√≥n 'Asistencia Eventos ANEIAP' de un archivo PDF con soporte de OCR.
    :param pdf_path: Ruta del archivo PDF.
    :return: Texto de la secci√≥n 'Asistencia Eventos ANEIAP'.
    """
    text = extract_text_with_ocr(pdf_path)

    # Palabras clave para identificar inicio y fin de la secci√≥n
    start_keyword = "ASISTENCIA A EVENTOS ANEIAP"
    end_keywords = [
        "ACTUALIZACI√ìN PROFESIONAL",
        "EXPERIENCIA EN ANEIAP",
        "EVENTOS ORGANIZADOS",
        "RECONOCIMIENTOS",
    ]

    # Encontrar √≠ndice de inicio
    start_idx = text.lower().find(start_keyword.lower())
    if start_idx == -1:
        return None  # No se encontr√≥ la secci√≥n

    # Encontrar √≠ndice m√°s cercano de fin basado en palabras clave
    end_idx = len(text)  # Por defecto, tomar hasta el final
    for keyword in end_keywords:
        idx = text.lower().find(keyword.lower(), start_idx)
        if idx != -1:
            end_idx = min(end_idx, idx)

    # Extraer la secci√≥n entre inicio y fin
    att_text = text[start_idx:end_idx].strip()

    # Filtrar y limpiar texto
    att_exclude_lines = [
        "a nivel capitular",
        "a nivel nacional",
        "a nivel seccional",
        "capitular",
        "seccional",
        "nacional",
    ]
    att_lines = att_text.split("\n")
    att_cleaned_lines = []
    for line in att_lines:
        line = line.strip()
        line = re.sub(r"[^\w\s]", "", line)  # Eliminar caracteres no alfanum√©ricos excepto espacios
        normalized_att_line = re.sub(r"\s+", " ", line).lower()  # Normalizar espacios y convertir a min√∫sculas
        if (
            normalized_att_line
            and normalized_att_line not in att_exclude_lines
            and normalized_att_line != start_keyword.lower()
            and normalized_att_line not in [kw.lower() for kw in end_keywords]
        ):
            att_cleaned_lines.append(line)

    return "\n".join(att_cleaned_lines)

    # Debugging: Imprime l√≠neas procesadas
    print("L√≠neas procesadas:")
    for line in att_cleaned_lines:
        print(f"- {line}")

    return "\n".join(att_cleaned_lines)

def generate_report_with_background_api(pdf_path, position, candidate_name,background_path, chapter):
    """
    Genera un reporte con un fondo en cada p√°gina for API usage, returns base64 encoded PDF.
    :param pdf_path: Ruta del PDF.
    :param position: Cargo al que aspira.
    :param candidate_name: Nombre del candidato.
    :param background_path: Ruta de la imagen de fondo.
    :param chapter: Cap√≠tulo del Candidato
    :return: base64 encoded PDF content and report path
    """
    experience_text = extract_experience_section_with_ocr(pdf_path)
    if not experience_text:
        return None, "No se encontr√≥ la secci√≥n 'EXPERIENCIA EN ANEIAP' en el PDF."

    org_text = extract_event_section_with_ocr(pdf_path)
    if not org_text:
        return None, "No se encontr√≥ la secci√≥n 'EVENTOS ORGANIZADOS' en el PDF."

    att_text = extract_attendance_section_with_ocr(pdf_path)
    if not att_text:
        return None, "No se encontr√≥ la secci√≥n 'Asistencia a Eventos ANEIAP' en el PDF."

    resume_text= evaluate_cv_presentation(pdf_path)
    if not resume_text:
        return None, "No se encontr√≥ el texto de la hoja de vida"

    candidate_profile_text= extract_profile_section_with_ocr(pdf_path)
    if not candidate_profile_text:
        return None, "No se encontr√≥ la secci√≥n 'Perfil' en el PDF."

    # Dividir la experiencia en l√≠neas
    lines = extract_cleaned_lines(experience_text)
    lines= experience_text.split("\n")
    lines = [line.strip() for line in lines if line.strip()]  # Eliminar l√≠neas vac√≠as

    # Dividir los eventos en l√≠neas
    org_lines = extract_cleaned_lines(org_text)
    org_lines= org_text.split("\n")
    org_lines = [line.strip() for line in org_lines if line.strip()]  # Eliminar l√≠neas vac√≠as

    #Dividir lineas de perfil
    candidate_profile_lines = extract_cleaned_lines(candidate_profile_text)
    candidate_profile_lines= candidate_profile_text.split("\n")
    candidate_profile_lines= [line.strip() for line in candidate_profile_lines if line.strip()]

    # Dividir la asistencia en l√≠neas
    att_lines = extract_cleaned_lines(att_text)
    att_lines= att_text.split("\n")
    att_lines = [line.strip() for line in att_lines if line.strip()]  # Eliminar l√≠neas vac√≠as

    # Obtener los indicadores y palabras clave para el cargo seleccionado
    position_indicators = indicators.get(position, {})

    indicator_results = calculate_all_indicators(lines, position_indicators)

    # Cargar funciones y perfil
    try:
        with fitz.open(f"Funciones//F{position}.pdf") as func_doc:
            functions_text = func_doc[0].get_text()
        with fitz.open(f"Perfiles/P{position}.pdf") as profile_doc:
            profile_text = profile_doc[0].get_text()
    except Exception as e:
        return None, f"Error al cargar funciones o perfil: {e}"

    line_results = []
    org_line_results = []
    att_line_results = []

    # Evaluaci√≥n de renglones de EXPERIENCIA EN ANEIAP
    # Evaluaci√≥n de renglones
    for line in lines:
        line = line.strip()
        if not line:  # Ignorar l√≠neas vac√≠as
            continue

        # Dividir la experiencia en l√≠neas
        lines = extract_cleaned_lines(experience_text)
        lines = experience_text.split("\n")
        lines = [line.strip() for line in lines if line.strip()]  # Eliminar l√≠neas vac√≠as

        # Obtener los indicadores y palabras clave para el cargo seleccionado
        position_indicators = indicators.get(position, {})
        indicator_results = {}

        # Calcular el porcentaje por cada indicador
        indicator_results = calculate_indicators_for_report(lines, position_indicators)
        for indicator, keywords in position_indicators.items():
            indicator_results = calculate_indicators_for_report(lines, position_indicators)

        # Calcular la presencia total (si es necesario)
        total_presence = sum(result["percentage"] for result in indicator_results.values())

        # Normalizar los porcentajes si es necesario
        if total_presence > 0:
            for indicator in indicator_results:
                indicator_results[indicator]["percentage"] = (indicator_results[indicator]["percentage"] / total_presence) * 100

        # Evaluaci√≥n general de concordancia
        if any(keyword.lower() in line.lower() for kw_set in position_indicators.values() for keyword in kw_set):
            func_match = 100.0
            profile_match = 100.0
        else:
            # Calcular similitud
            func_match = calculate_similarity(line, functions_text)
            profile_match = calculate_similarity(line, profile_text)

        # Solo agregar al reporte si no tiene 0% en ambas m√©tricas
        if func_match > 0 or profile_match > 0:
            line_results.append((line, func_match, profile_match))

    # Normalizaci√≥n de los resultados de indicadores
    total_presence = sum(indicator["percentage"] for indicator in indicator_results.values())
    if total_presence > 0:
        for indicator in indicator_results:
            indicator_results[indicator]["percentage"] = (indicator_results[indicator]["percentage"] / total_presence) * 100

    # Evaluaci√≥n de renglones eventos organizados
    for line in org_lines:
        line = line.strip()
        if not line:  # Ignorar l√≠neas vac√≠as
            continue

        # Dividir los eventos en l√≠neas
        org_lines = extract_cleaned_lines(org_text)
        org_lines= att_text.split("\n")
        org_lines = [line.strip() for line in org_lines if line.strip]

        # Evaluaci√≥n general de concordancia
        if any(keyword.lower() in line.lower() for kw_set in position_indicators.values() for keyword in kw_set):
            org_func_match = 100.0
            org_profile_match = 100.0
        else:
            # Calcular similitud
            org_func_match = calculate_similarity(line, functions_text)
            org_profile_match = calculate_similarity(line, profile_text)

        # Solo agregar al reporte si no tiene 0% en ambas m√©tricas
        if org_func_match > 0 or org_profile_match > 0:
            org_line_results.append((line, org_func_match, org_profile_match))

    # Evaluaci√≥n de renglones asistencia a eventos
    for line in att_lines:
        line = line.strip()
        if not line:  # Ignorar l√≠neas vac√≠as
            continue

        # Dividir los asistencia en l√≠neas
        att_lines = extract_cleaned_lines(att_text)
        att_lines= att_text.split("\n")
        att_lines = [line.strip() for line in att_lines if line.strip]

        # Evaluaci√≥n general de concordancia
        if any(keyword.lower() in line.lower() for kw_set in position_indicators.values() for keyword in kw_set):
            att_func_match = 100.0
            att_profile_match = 100.0
        else:
            # Calcular similitud
            att_func_match = calculate_similarity(line, functions_text)
            att_profile_match = calculate_similarity(line, profile_text)

        # Solo agregar al reporte si no tiene 0% en ambas m√©tricas
        if att_func_match > 0 or att_profile_match > 0:
            att_line_results.append((line, att_func_match, att_profile_match))

    # Calcular porcentajes de concordancia con perfil de candidato
    keyword_count = 0
    words = re.findall(r"\b\w+\b", candidate_profile_text)
    total_words = len(words)
    for kw_set in position_indicators.values():
        for keyword in kw_set:
            keyword_count += candidate_profile_text.count(keyword)

    prop_keyword= keyword_count/total_words

    # Evitar divisi√≥n por cero
    if prop_keyword<= 0.01:
        keyword_match_percentage = 0
    elif 0.01 <prop_keyword <= 0.15:
        keyword_match_percentage = 25
    elif 0.15 <prop_keyword <= 0.5:
        keyword_match_percentage = 50
    elif 0.5 <prop_keyword <= 0.75:
        keyword_match_percentage = 75
    else:
        keyword_match_percentage = 100

    # Evaluaci√≥n de concordancia basada en palabras clave
    if keyword_match_percentage == 100:
        profile_func_match = 100.0
        profile_profile_match = 100.0
    else:
        # Calcular similitud con funciones y perfil del cargo si la coincidencia es baja
        prof_func_match = calculate_similarity(candidate_profile_text, functions_text)
        prof_profile_match = calculate_similarity(candidate_profile_text, profile_text)
        profile_func_match = keyword_match_percentage + prof_func_match
        profile_profile_match = keyword_match_percentage + prof_profile_match

    # Calcular porcentajes parciales respecto a la Experiencia ANEIAP
    if line_results:  # Evitar divisi√≥n por cero si no hay √≠tems v√°lidos
        parcial_exp_func_match = sum([res[1] for res in line_results]) / len(line_results)
        parcial_exp_profile_match = sum([res[2] for res in line_results]) / len(line_results)
    else:
        parcial_exp_func_match = 0
        parcial_exp_profile_match = 0

    # Calcular porcentajes parciales respecto a los Eventos ANEIAP
    if org_line_results:  # Evitar divisi√≥n por cero si no hay √≠tems v√°lidos
        parcial_org_func_match = sum([res[1] for res in org_line_results]) / len(org_line_results)
        parcial_org_profile_match = sum([res[2] for res in org_line_results]) / len(org_line_results)
    else:
        parcial_org_func_match = 0
        parcial_org_profile_match = 0

    # Calcular porcentajes parciales respecto a la asistencia a eventos
    if att_line_results:  # Evitar divisi√≥n por cero si no hay √≠tems v√°lidos
        parcial_att_func_match = sum([res[1] for res in att_line_results]) / len(att_line_results)
        parcial_att_profile_match = sum([res[2] for res in att_line_results]) / len(att_line_results)
    else:
        parcial_att_func_match = 0
        parcial_att_profile_match = 0

    resume_text= evaluate_cv_presentation(pdf_path)

    # Inicializar corrector ortogr√°fico
    spell = SpellChecker(language='es')

    punctuation_errors = 0

    for i, line in enumerate(lines):
        # Verificar si la oraci√≥n termina con puntuaci√≥n v√°lida
        if not line.endswith((".", "!", "?")):
            punctuation_errors += 1

    # Limpiar y dividir el texto en l√≠neas
    pres_cleaned_lines = [line.strip() for line in resume_text.split("\n") if line.strip()]
    total_lines = len(pres_cleaned_lines)

    # M√©tricas
    total_words = 0
    spelling_errors = 0
    missing_capitalization = 0
    incomplete_sentences = 0
    punctuation_marks = 0
    grammar_errors = 0

    for line in pres_cleaned_lines:
        # Dividir en palabras y contar
        words = re.findall(r'\b\w+\b', line)
        total_words += len(words)

        # Ortograf√≠a
        misspelled = spell.unknown(words)
        spelling_errors += len(misspelled)

        # Verificar capitalizaci√≥n
        if line and not line[0].isupper():
            missing_capitalization += 1

        # Verificar que termine en signo de puntuaci√≥n
        if not line.endswith((".", "!", "?", ":", ";")):
            incomplete_sentences += 1

        # Gram√°tica b√°sica: verificar patrones comunes (ejemplo)
        grammar_errors += len(re.findall(r'\b(?:es|est√°|son)\b [^\w\s]', line))  # Ejemplo: "es" sin continuaci√≥n v√°lida

    # Calcular m√©tricas secundarias
    spelling = 1- (spelling_errors / total_words)
    capitalization_score = 1- (missing_capitalization / total_lines)
    sentence_completion_score = 1- (incomplete_sentences / total_lines)
    grammar = 1- (grammar_errors / total_lines)
    punctuation_error_rate = 1- (punctuation_errors / total_lines)

    #Calcular m√©tricas principales
    grammar_score = round(((punctuation_error_rate+ grammar+ sentence_completion_score)/3)*5, 2)
    spelling_score= round(((spelling+ capitalization_score)/2)*5,2)

    if total_lines == 0:
        return 100  # Si no hay oraciones, asumimos coherencia perfecta.

    # Calcular m√©tricas coherencia
    # 1. Repetici√≥n de palabras
    def calculate_word_repetition(pres_cleaned_lines):
        repeated_words = Counter()
        for line in pres_cleaned_lines:
            words = line.split()
            repeated_words.update([word.lower() for word in words])

        total_words = sum(repeated_words.values())
        unique_words = len(repeated_words)
        most_common_word_count = repeated_words.most_common(1)[0][1] if repeated_words else 0
        repeated_word_ratio = (most_common_word_count / total_words) if total_words > 0 else 0

        # Una menor repetici√≥n indica mayor calidad
        repetition_score = 1 - repeated_word_ratio
        return repetition_score, repeated_words

    # 2. Fluidez entre oraciones
    def calculate_sentence_fluency(pres_cleaned_lines):
        """
        Calcula el puntaje de fluidez de las oraciones bas√°ndose en conectores l√≥gicos, puntuaci√≥n,
        y variabilidad en la longitud de las oraciones.
        :param pres_cleaned_lines: Lista de l√≠neas limpias del texto.
        :return: Puntaje de fluidez de las oraciones entre 0 y 1.
        """
        # Lista de conectores l√≥gicos comunes
        logical_connectors = {
        "adici√≥n": [
            "adem√°s", "tambi√©n", "asimismo", "igualmente", "de igual manera",
            "por otro lado", "de la misma forma", "junto con"
        ],
        "causa": [
            "porque", "ya que", "debido a", "dado que", "por motivo de",
            "gracias a", "en raz√≥n de", "a causa de"
        ],
        "consecuencia": [
            "por lo tanto", "as√≠ que", "en consecuencia", "como resultado",
            "por esta raz√≥n", "de modo que", "lo que permiti√≥", "de ah√≠ que"
        ],
        "contraste": [
            "sin embargo", "pero", "aunque", "no obstante", "a pesar de",
            "por el contrario", "en cambio", "si bien", "mientras que"
        ],
        "condici√≥n": [
            "si", "en caso de", "a menos que", "siempre que", "con la condici√≥n de",
            "a no ser que", "en el supuesto de que"
        ],
        "tiempo": [
            "mientras", "cuando", "despu√©s de", "antes de", "al mismo tiempo",
            "posteriormente", "una vez que", "simult√°neamente", "en el transcurso de"
        ],
        "descripci√≥n de funciones": [
            "encargado de", "responsable de", "mis funciones inclu√≠an",
            "lider√©", "gestion√©", "coordin√©", "dirig√≠", "supervis√©",
            "desarroll√©", "planifiqu√©", "ejecut√©", "implement√©", "organic√©"
        ],
        "logros y resultados": [
            "logr√©", "alcanc√©", "consegu√≠", "increment√©", "reduje",
            "optimiz√©", "mejor√©", "aument√©", "potenci√©", "maximic√©",
            "contribu√≠ a", "obtuve", "permiti√≥ mejorar", "impact√≥ positivamente en"
        ],
        "secuencia": [
            "primero", "en primer lugar", "a continuaci√≥n", "luego", "despu√©s",
            "seguidamente", "posteriormente", "finalmente", "por √∫ltimo"
        ],
        "√©nfasis": [
            "sobre todo", "en particular", "especialmente", "principalmente",
            "espec√≠ficamente", "vale la pena destacar", "conviene resaltar",
            "cabe mencionar", "es importante se√±alar"
        ],
        "conclusi√≥n": [
            "en resumen", "para concluir", "en definitiva", "en s√≠ntesis",
            "como conclusi√≥n", "por ende", "por consiguiente", "para finalizar"
        ]
    }
        connector_count = 0
        total_lines = len(pres_cleaned_lines)

        # Validaci√≥n para evitar divisiones por cero
        if total_lines == 0:
            return 0  # Sin l√≠neas, no se puede calcular fluidez

        # Inicializaci√≥n de m√©tricas
        punctuation_errors = 0
        sentence_lengths = []

        for line in pres_cleaned_lines:
            # Verificar errores de puntuaci√≥n (oraciones sin punto final)
            if not line.endswith((".", "!", "?")):
                punctuation_errors += 1

            # Almacenar la longitud de cada oraci√≥n
            sentence_lengths.append(len(line.split()))

            # Contar conectores l√≥gicos en la l√≠nea
            for connector in logical_connectors:
                if connector in line.lower():
                    connector_count += 1

        # Calcular m√©tricas individuales
        avg_length = sum(sentence_lengths) / total_lines
        length_variance = sum(
            (len(line.split()) - avg_length) ** 2 for line in pres_cleaned_lines
        ) / total_lines if total_lines > 1 else 0

        # Normalizar m√©tricas entre 0 y 1
        punctuation_score = max(0, 1 - (punctuation_errors / total_lines))  # 1 si no hay errores
        connector_score = min(1, connector_count / total_lines)  # M√°ximo 1, basado en conectores
        variance_penalty = max(0, 1 - length_variance / avg_length) if avg_length > 0 else 0

        # Calcular puntaje final de fluidez
        fluency_score = (punctuation_score + connector_score + variance_penalty) / 3
        return round(fluency_score, 2)


    # Calcular m√©tricas individuales
    repetition_score, repeated_words = calculate_word_repetition(pres_cleaned_lines)
    fluency_score = calculate_sentence_fluency(pres_cleaned_lines)

    # Asegurar que repetition_score y fluency_score est√°n entre 0 y 1 antes de la conversi√≥n
    normalized_repetition_score = min(1, max(0, repetition_score))
    normalized_fluency_score = min(1, max(0, fluency_score))

    # Calcular coherencia asegurando que el resultado final no pase de 5
    coherence_score = round(min(5, (normalized_repetition_score + normalized_fluency_score) * 2.5), 2)

    # Puntaje general ponderado
    overall_score = round((spelling_score  + coherence_score + grammar_score) / 3, 2)

    # Calculo puntajes parciales
    parcial_exp_func_score = round((parcial_exp_func_match * 5) / 100, 2)
    parcial_exp_profile_score = round((parcial_exp_profile_match * 5) / 100, 2)
    parcial_org_func_score = round((parcial_org_func_match * 5) / 100, 2)
    parcial_org_profile_score = round((parcial_org_profile_match * 5) / 100, 2)
    parcial_att_func_score = round((parcial_att_func_match * 5) / 100, 2)
    parcial_att_profile_score = round((parcial_att_profile_match * 5) / 100, 2)
    profile_func_score= round((profile_func_match * 5) / 100, 2)
    profile_profile_score= round((profile_profile_match * 5) / 100, 2)

    #Calcular resultados globales
    global_func_match = (parcial_exp_func_match + parcial_att_func_match + parcial_org_func_match+ profile_func_match) / 4
    global_profile_match = (parcial_exp_profile_match + parcial_att_profile_match + parcial_org_profile_match + profile_profile_match) / 4
    func_score = round((global_func_match * 5) / 100, 2)
    profile_score = round((global_profile_match * 5) / 100, 2)

    #Calculo puntajes totales
    exp_score= (parcial_exp_func_score+ parcial_exp_profile_score)/2
    org_score= (parcial_org_func_score+ parcial_org_profile_score)/2
    att_score= (parcial_att_func_score+ parcial_att_profile_score)/2
    prof_score= (profile_func_score+ profile_profile_score)/2
    total_score= (overall_score+ exp_score+ org_score+ att_score+ profile_score)/5

    # Registrar la fuente personalizada
    pdfmetrics.registerFont(TTFont('CenturyGothic', 'Century_Gothic.ttf'))
    pdfmetrics.registerFont(TTFont('CenturyGothicBold', 'Century_Gothic_Bold.ttf'))

    # Estilos
    styles = getSampleStyleSheet()
    styles.add(ParagraphStyle(name="CenturyGothic", fontName="CenturyGothic", fontSize=12, leading=14, alignment=TA_JUSTIFY))
    styles.add(ParagraphStyle(name="CenturyGothicBold", fontName="CenturyGothicBold", fontSize=12, leading=14, alignment=TA_JUSTIFY))

    # Crear el documento PDF
    report_path = f"Reporte_analisis_cargo_{candidate_name}_{position}_{chapter}.pdf"
    doc = SimpleDocTemplate(report_path, pagesize=letter, rightMargin=72, leftMargin=72, topMargin=100, bottomMargin=72)

    # Lista de elementos para el reporte
    elements = []

    # üìå **3Ô∏è‚É£ AGREGAR PORTADA SIN FONDO**
    def on_first_page(canvas, doc):
        """Dibuja una portada que ocupa toda la p√°gina."""
        draw_full_page_cover(canvas, portada_path, candidate_name, position, chapter)

    # T√≠tulo del reporte centrado
    title_style = ParagraphStyle(name='CenteredTitle', fontName='CenturyGothicBold', fontSize=14, leading=16, alignment=1,  # 1 significa centrado, textColor=colors.black
                                )
    # Convertir texto a may√∫sculas
    elements.append(PageBreak())
    title_candidate_name = candidate_name.upper()
    title_position = position.upper()
    tittle_chapter= chapter.upper()

    elements.append(Paragraph(f"REPORTE DE AN√ÅLISIS {title_candidate_name} CARGO {title_position} {tittle_chapter}", title_style))

    elements.append(Spacer(1, 0.2 * inch))

    # Concordancia de items organizada en tabla con ajuste de texto
    elements.append(Paragraph("<b>An√°lisis de perfil de aspirante:</b>", styles['CenturyGothicBold']))
    elements.append(Spacer(1, 0.2 * inch))

    # Encabezados de la tabla
    prof_table_data = [["√çtem", "Funciones del Cargo (%)", "Perfil del Cargo (%)"]]

    #Agregar resultados parciales
    prof_table_data.append([Paragraph("<b>Concordancia Parcial</b>", styles['CenturyGothicBold']), f"{profile_func_match:.2f}%", f"{profile_profile_match:.2f}%"])
    prof_table_data.append([Paragraph("<b>Puntaje Parcial</b>", styles['CenturyGothicBold']), f"{profile_func_score:.2f}", f"{profile_profile_score:.2f}"])

    # Crear la tabla con ancho de columnas ajustado
    prof_item_table = Table(prof_table_data, colWidths=[3 * inch, 2 * inch, 2 * inch])

    # Estilos de la tabla con ajuste de texto
    prof_item_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor("#F0F0F0")),  # Fondo para encabezados
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),  # Color de texto en encabezados
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),  # Alinear texto al centro
        ('FONTNAME', (0, 0), (-1, 0), 'CenturyGothicBold'),  # Fuente para encabezados
        ('FONTNAME', (0, 1), (-1, -1), 'CenturyGothic'),  # Fuente para el resto de la tabla
        ('FONTSIZE', (0, 0), (-1, -1), 10),  # Tama√±o de fuente
        ('BOTTOMPADDING', (0, 0), (-1, 0), 8),  # Padding inferior para encabezados
        ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),  # L√≠neas de la tabla
        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),  # Alinear texto verticalmente al centro
        ('WORDWRAP', (0, 0), (-1, -1)),  # Habilitar ajuste de texto
    ]))

    # Agregar tabla a los elementos
    elements.append(prof_item_table)

    elements.append(Spacer(1, 0.2 * inch))

    # Concordancia de items organizada en tabla con ajuste de texto
    elements.append(Paragraph("<b>An√°lisis de √≠tems de asistencia a eventos:</b>", styles['CenturyGothicBold']))
    elements.append(Spacer(1, 0.2 * inch))

    # Encabezados de la tabla
    att_table_data = [["√çtem", "Funciones del Cargo (%)", "Perfil del Cargo (%)"]]

    # Agregar datos de line_results a la tabla
    for line, att_func_match, att_profile_match in att_line_results:
        att_table_data.append([Paragraph(line, styles['CenturyGothic']), f"{att_func_match:.2f}%", f"{att_profile_match:.2f}%"])

    #Agregar resultados parciales
    att_table_data.append([Paragraph("<b>Concordancia Parcial</b>", styles['CenturyGothicBold']), f"{parcial_att_func_match:.2f}%", f"{parcial_att_profile_match:.2f}%"])
    att_table_data.append([Paragraph("<b>Puntaje Parcial</b>", styles['CenturyGothicBold']), f"{parcial_att_func_score:.2f}", f"{parcial_att_profile_score:.2f}"])

    # Crear la tabla con ancho de columnas ajustado
    att_item_table = Table(att_table_data, colWidths=[3 * inch, 2 * inch, 2 * inch])

    # Estilos de la tabla con ajuste de texto
    att_item_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor("#F0F0F0")),  # Fondo para encabezados
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),  # Color de texto en encabezados
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),  # Alinear texto al centro
        ('FONTNAME', (0, 0), (-1, 0), 'CenturyGothicBold'),  # Fuente para encabezados
        ('FONTNAME', (0, 1), (-1, -1), 'CenturyGothic'),  # Fuente para el resto de la tabla
        ('FONTSIZE', (0, 0), (-1, -1), 10),  # Tama√±o de fuente
        ('BOTTOMPADDING', (0, 0), (-1, 0), 8),  # Padding inferior para encabezados
        ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),  # L√≠neas de la tabla
        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),  # Alinear texto verticalmente al centro
        ('WORDWRAP', (0, 0), (-1, -1)),  # Habilitar ajuste de texto
    ]))

    # Agregar tabla a los elementos
    elements.append(att_item_table)

    elements.append(Spacer(1, 0.1 * inch))

    # Total de l√≠neas analizadas en ASISTENCIA A EVENTOS ANEIAP
    att_total_lines = len(att_line_results)
    elements.append(Paragraph(f"‚Ä¢ Total de asistencias a eventos analizadas: {att_total_lines}", styles['CenturyGothicBold']))

    elements.append(Spacer(1, 0.2 * inch))

    # Concordancia de items organizada en tabla con ajuste de texto
    elements.append(Paragraph("<b>An√°lisis de √≠tems de eventos organizados:</b>", styles['CenturyGothicBold']))
    elements.append(Spacer(1, 0.2 * inch))

    # Encabezados de la tabla
    org_table_data = [["√çtem", "Funciones del Cargo (%)", "Perfil del Cargo (%)"]]

    # Agregar datos de line_results a la tabla
    for line, org_func_match, org_profile_match in org_line_results:
        org_table_data.append([Paragraph(line, styles['CenturyGothic']), f"{org_func_match:.2f}%", f"{org_profile_match:.2f}%"])

    #Agregar resultados parciales
    org_table_data.append([Paragraph("<b>Concordancia Parcial</b>", styles['CenturyGothicBold']), f"{parcial_org_func_match:.2f}%", f"{parcial_org_profile_match:.2f}%"])
    org_table_data.append([Paragraph("<b>Puntaje Parcial</b>", styles['CenturyGothicBold']), f"{parcial_org_func_score:.2f}", f"{parcial_org_profile_score:.2f}"])

    # Crear la tabla con ancho de columnas ajustado
    org_item_table = Table(org_table_data, colWidths=[3 * inch, 2 * inch, 2 * inch])

    # Estilos de la tabla con ajuste de texto
    org_item_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor("#F0F0F0")),  # Fondo para encabezados
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),  # Color de texto en encabezados
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),  # Alinear texto al centro
        ('FONTNAME', (0, 0), (-1, 0), 'CenturyGothicBold'),  # Fuente para encabezados
        ('FONTNAME', (0, 1), (-1, -1), 'CenturyGothic'),  # Fuente para el resto de la tabla
        ('FONTSIZE', (0, 0), (-1, -1), 10),  # Tama√±o de fuente
        ('BOTTOMPADDING', (0, 0), (-1, 0), 8),  # Padding inferior para encabezados
        ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),  # L√≠neas de la tabla
        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),  # Alinear texto verticalmente al centro
        ('WORDWRAP', (0, 0), (-1, -1)),  # Habilitar ajuste de texto
    ]))

    # Agregar tabla a los elementos
    elements.append(org_item_table)

    elements.append(Spacer(1, 0.1 * inch))

    # Total de l√≠neas analizadas en ASISTENCIA A EVENTOS ANEIAP
    org_total_lines = len(org_line_results)
    elements.append(Paragraph(f"‚Ä¢ Total de eventos analizados: {org_total_lines}", styles['CenturyGothicBold']))

    elements.append(Spacer(1, 0.2 * inch))

    # Concordancia de items organizada en tabla con ajuste de texto
    elements.append(Paragraph("<b>An√°lisis de √≠tems:</b>", styles['CenturyGothicBold']))
    elements.append(Spacer(1, 0.2 * inch))

    # Encabezados de la tabla
    table_data = [["√çtem", "Funciones del Cargo (%)", "Perfil del Cargo (%)"]]

    # Agregar datos de line_results a la tabla
    for line, exp_func_match, exp_profile_match in line_results:
        table_data.append([Paragraph(line, styles['CenturyGothic']), f"{exp_func_match:.2f}%", f"{exp_profile_match:.2f}%"])

    #Agregar resultados parciales
    table_data.append([Paragraph("<b>Concordancia Parcial</b>", styles['CenturyGothicBold']), f"{parcial_exp_func_match:.2f}%", f"{parcial_exp_profile_match:.2f}%"])
    table_data.append([Paragraph("<b>Puntaje Parcial</b>", styles['CenturyGothicBold']), f"{parcial_exp_func_score:.2f}", f"{parcial_exp_profile_score:.2f}"])

    # Crear la tabla con ancho de columnas ajustado
    item_table = Table(table_data, colWidths=[3 * inch, 2 * inch, 2 * inch])

    # Estilos de la tabla con ajuste de texto
    item_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor("#F0F0F0")),  # Fondo para encabezados
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),  # Color de texto en encabezados
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),  # Alinear texto al centro
        ('FONTNAME', (0, 0), (-1, 0), 'CenturyGothicBold'),  # Fuente para encabezados
        ('FONTNAME', (0, 1), (-1, -1), 'CenturyGothic'),  # Fuente para el resto de la tabla
        ('FONTSIZE', (0, 0), (-1, -1), 10),  # Tama√±o de fuente
        ('BOTTOMPADDING', (0, 0), (-1, 0), 8),  # Padding inferior para encabezados
        ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),  # L√≠neas de la tabla
        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),  # Alinear texto verticalmente al centro
        ('WORDWRAP', (0, 0), (-1, -1)),  # Habilitar ajuste de texto
    ]))

    # Agregar tabla a los elementos
    elements.append(item_table)

    elements.append(Spacer(1, 0.2 * inch))

    # Total de l√≠neas analizadas en EXPERIENCIA EN ANEIAP
    total_lines = len(line_results)
    elements.append(Paragraph(f"‚Ä¢ Total de experiencias analizadas: {total_lines}", styles['CenturyGothicBold']))

    elements.append(Spacer(1, 0.2 * inch))

    # A√±adir resultados al reporte
    elements.append(Paragraph("<b>Evaluaci√≥n de la Presentaci√≥n:</b>", styles['CenturyGothicBold']))
    elements.append(Spacer(1, 0.2 * inch))

    # Crear tabla de evaluaci√≥n de presentaci√≥n
    presentation_table = Table(
        [
            ["Criterio", "Puntaje"],
            ["Coherencia", f"{coherence_score:.2f}"],
            ["Ortograf√≠a", f"{spelling_score:.2f}"],
            ["Gram√°tica", f"{grammar_score:.2f}"],
            ["Puntaje Total", f"{overall_score:.2f}"]
        ],
        colWidths=[3 * inch, 2 * inch]
    )

    # Estilo de la tabla
    presentation_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor("#F0F0F0")),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
        ('FONTNAME', (0, 0), (-1, 0), 'CenturyGothicBold'),
        ('FONTNAME', (0, 1), (-1, -1), 'CenturyGothic'),
        ('FONTSIZE', (0, 0), (-1, -1), 10),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 8),
        ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),
        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
    ]))

    elements.append(presentation_table)

    elements.append(Spacer(1, 0.2 * inch))

    elements.append(Paragraph("<b>Consejos para mejorar la presentaci√≥n de la hoja de vida:</b>", styles['CenturyGothicBold']))
    elements.append(Spacer(1, 0.2 * inch))

    elements.append(Spacer(1, 0.2 * inch))
    # Concordancia de items organizada en tabla con ajuste de texto
    elements.append(Paragraph("<b>Resultados de indicadores:</b>", styles['CenturyGothicBold']))
    elements.append(Spacer(1, 0.2 * inch))

    # Encabezados de la tabla
    table_indicator = [["Indicador", "Concordancia (%)"]]

    # Agregar datos de line_results a la tabla
    for indicator, data in indicator_results.items():
        relevant_lines = sum(
            any(keyword.lower() in line.lower() for keyword in keywords) for line in lines
        )
        total_lines = len(line_results)
        percentage = (relevant_lines / total_lines) * 100 if total_lines > 0 else 0
        if isinstance(percentage, (int, float)):  # Validar que sea un n√∫mero
            table_indicator.append([Paragraph(indicator, styles['CenturyGothic']), f"{percentage:.2f}%"])

    # Crear la tabla con ancho de columnas ajustado
    indicator_table = Table(table_indicator, colWidths=[3 * inch, 2 * inch, 2 * inch])

    # Estilos de la tabla con ajuste de texto
    indicator_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor("#F0F0F0")),  # Fondo para encabezados
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),  # Color de texto en encabezados
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),  # Alinear texto al centro
        ('FONTNAME', (0, 0), (-1, 0), 'CenturyGothicBold'),  # Fuente para encabezados
        ('FONTNAME', (0, 1), (-1, -1), 'CenturyGothic'),  # Fuente para el resto de la tabla
        ('FONTSIZE', (0, 0), (-1, -1), 10),  # Tama√±o de fuente
        ('BOTTOMPADDING', (0, 0), (-1, 0), 8),  # Padding inferior para encabezados
        ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),  # L√≠neas de la tabla
        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),  # Alinear texto verticalmente al centro
        ('WORDWRAP', (0, 0), (-1, -1)),  # Habilitar ajuste de texto
    ]))

    # Agregar tabla a los elementos
    elements.append(indicator_table)

    elements.append(Spacer(1, 0.2 * inch))

    # Consejos para mejorar indicadores con baja presencia
    low_performance_indicators = {k: v for k, v in indicator_results.items() if (relevant_lines/ total_lines) * 100 < 60.0}
    if low_performance_indicators:
        elements.append(Paragraph("<b>Consejos para Mejorar:</b>", styles['CenturyGothicBold']))
        elements.append(Spacer(1, 0.05 * inch))
        for indicator, result in low_performance_indicators.items():
            percentage = (relevant_lines/ total_lines)*100
            elements.append(Paragraph(f" {indicator}: ({percentage:.2f}%)", styles['CenturyGothicBold']))
            elements.append(Spacer(1, 0.05 * inch))
            for tip in advice[position].get(indicator, []):
                elements.append(Paragraph(f"  ‚Ä¢ {tip}", styles['CenturyGothic']))
                elements.append(Spacer(1, 0.1 * inch))

    elements.append(Spacer(1, 0.2 * inch))

   # Concordancia de items organizada en tabla global con ajuste de texto
    elements.append(Paragraph("<b>Resultados globales:</b>", styles['CenturyGothicBold']))

    elements.append(Spacer(1, 0.2 * inch))

    # Encabezados de la tabla global
    global_table_data = [["Criterio","Funciones del Cargo", "Perfil del Cargo"]]

    # Agregar datos de global_results a la tabla
    global_table_data.append([Paragraph("<b>Concordancia Global</b>", styles['CenturyGothicBold']), f"{global_func_match:.2f}%", f"{global_profile_match:.2f}%"])
    global_table_data.append([Paragraph("<b>Puntaje Global</b>", styles['CenturyGothicBold']), f"{func_score:.2f}", f"{profile_score:.2f}"])

    # Crear la tabla con ancho de columnas ajustado
    global_table = Table(global_table_data, colWidths=[3 * inch, 2 * inch, 2 * inch])

    # Estilos de la tabla con ajuste de texto
    global_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor("#F0F0F0")),  # Fondo para encabezados
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),  # Color de texto en encabezados
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),  # Alinear texto al centro
        ('FONTNAME', (0, 0), (-1, 0), 'CenturyGothicBold'),  # Fuente para encabezados
        ('FONTNAME', (0, 1), (-1, -1), 'CenturyGothic'),  # Fuente para el resto de la tabla
        ('FONTSIZE', (0, 0), (-1, -1), 10),  # Tama√±o de fuente
        ('BOTTOMPADDING', (0, 0), (-1, 0), 8),  # Padding inferior para encabezados
        ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),  # L√≠neas de la tabla
        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),  # Alinear texto verticalmente al centro
        ('WORDWRAP', (0, 0), (-1, -1)),  # Habilitar ajuste de texto
    ]))

    # Agregar tabla a los elementos
    elements.append(global_table)

    elements.append(Spacer(1, 0.2 * inch))

    # Interpretaci√≥n de resultados
    elements.append(Paragraph("<b>Interpretaci√≥n de resultados globales:</b>", styles['CenturyGothicBold']))
    elements.append(Spacer(1, 0.1 * inch))
    if global_profile_match > 75 and global_func_match > 75:
        elements.append(Paragraph(
            f" Alta Concordancia (> 0.75): El an√°lisis revela que {candidate_name} tiene una excelente adecuaci√≥n con las funciones del cargo de {position} y el perfil buscado. La experiencia detallada en su hoja de vida est√° estrechamente alineada con las responsabilidades y competencias requeridas para este rol crucial en la prevalencia del Cap√≠tulo. La alta concordancia indica que {candidate_name} est√° bien preparado para asumir este cargo y contribuir significativamente al √©xito y la misi√≥n del Cap√≠tulo. Se recomienda proceder con el proceso de selecci√≥n y considerar a {candidate_name} como una opci√≥n s√≥lida para el cargo.",
            styles['CenturyGothic']
        ))
    elif 60 < global_profile_match <= 75 or 60 < global_func_match <= 75:
        elements.append(Paragraph(
            f" Buena Concordancia (> 0.60): El an√°lisis muestra que {candidate_name} tiene una buena correspondencia con las funciones del cargo de {position} y el perfil deseado. Aunque su experiencia en la asociaci√≥n es relevante, existe margen para mejorar. {candidate_name} muestra potencial para cumplir con el rol crucial en la prevalencia del Cap√≠tulo, pero se recomienda que contin√∫e desarrollando sus habilidades y acumulando m√°s experiencia relacionada con el cargo objetivo. Su candidatura debe ser considerada con la recomendaci√≥n de enriquecimiento adicional.",
            styles['CenturyGothic']
        ))
    elif 60 < global_profile_match or 60 < global_func_match:
        elements.append(Paragraph(
            f" Baja Concordancia (< 0.60): El an√°lisis indica que {candidate_name} tiene una baja concordancia con los requisitos del cargo de {position} y el perfil buscado. Esto sugiere que aunque el aspirante posee algunas experiencias relevantes, su historial actual no cubre adecuadamente las competencias y responsabilidades necesarias para este rol crucial en la prevalencia del Cap√≠tulo. Se aconseja a {candidate_name} enfocarse en mejorar su perfil profesional y desarrollar las habilidades necesarias para el cargo. Este enfoque permitir√° a {candidate_name} alinear mejor su perfil con los requisitos del puesto en futuras oportunidades.",
            styles['CenturyGothic']
        ))

    elements.append(Spacer(1, 0.2 * inch))

    # A√±adir resultados al reporte
    elements.append(Paragraph("<b>Puntajes totales:</b>", styles['CenturyGothicBold']))
    elements.append(Spacer(1, 0.2 * inch))

    total_score= (exp_score+ att_score+ org_score+ round_overall_score+ profile_score)/5

    # Crear tabla de evaluaci√≥n de presentaci√≥n
    total_table = Table(
        [
            ["Criterio", "Puntaje"],
            ["Experiencia en ANEIAP", f"{exp_score:.2f}"],
            ["Asistencia a eventos", f"{att_score:.2f}"],
            ["Eventos organizados", f"{org_score:.2f}"],
            ["Perfil", f"{prof_score:.2f}"],
            ["Presentaci√≥n", f"{round_overall_score:.2f}"],
            ["Puntaje Total", f"{total_score:.2f}"]
        ],
        colWidths=[3 * inch, 2 * inch]
    )

    # Estilo de la tabla
    total_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor("#F0F0F0")),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
        ('FONTNAME', (0, 0), (-1, 0), 'CenturyGothicBold'),
        ('FONTNAME', (0, 1), (-1, -1), 'CenturyGothic'),
        ('FONTSIZE', (0, 0), (-1, -1), 10),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 8),
        ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),
        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
    ]))

    elements.append(total_table)

    elements.append(Spacer(1, 0.2 * inch))

    # Generar comentarios para los resultados
    comments = []

    if exp_score >= 4:
        comments.append("Tu experiencia en ANEIAP refleja un nivel destacado, lo que demuestra un conocimiento s√≥lido de la organizaci√≥n y tus contribuciones en actividades clave. Contin√∫a fortaleciendo tu participaci√≥n para mantener este nivel y destacar a√∫n m√°s.")
    elif exp_score >= 3:
        comments.append("Tu experiencia en ANEIAP es buena, pero podr√≠as enfocarte en profundizar tus contribuciones y participaci√≥n en actividades clave.")
    else:
        comments.append("Es importante fortalecer tu experiencia en ANEIAP. Considera involucrarte en m√°s actividades y proyectos para adquirir una mayor comprensi√≥n y relevancia.")

    if att_score >= 4:
        comments.append("Tu puntuaci√≥n en asistencia a eventos es excelente. Esto muestra tu compromiso con el aprendizaje y el desarrollo profesional. Mant√©n esta consistencia participando en eventos relevantes que sigan ampliando tu red de contactos y conocimientos.")
    elif att_score >= 3:
        comments.append("Tu asistencia a eventos es adecuada, pero hay margen para participar m√°s en actividades que refuercen tu aprendizaje y crecimiento profesional.")
    else:
        comments.append("Debes trabajar en tu participaci√≥n en eventos. La asistencia regular a actividades puede ayudarte a desarrollar habilidades clave y expandir tu red de contactos.")

    if org_score >= 4:
        comments.append("¬°Perfecto! Tu desempe√±o en la organizaci√≥n de eventos es ejemplar. Esto indica habilidades destacadas de planificaci√≥n, liderazgo y ejecuci√≥n. Considera compartir tus experiencias con otros miembros para fortalecer el impacto organizacional.")
    elif org_score >= 3:
        comments.append("Tu desempe√±o en la organizaci√≥n de eventos es bueno, pero podr√≠as centrarte en mejorar la planificaci√≥n y la ejecuci√≥n para alcanzar un nivel m√°s destacado.")
    else:
        comments.append("Es importante trabajar en tus habilidades de organizaci√≥n de eventos. Considera involucrarte en proyectos donde puedas asumir un rol de liderazgo y planificaci√≥n.")

    if prof_score >= 4:
        comments.append("Tu perfil presenta una buena alineaci√≥n con las expectativas del cargo, destacando competencias clave. Mant√©n este nivel y contin√∫a fortaleciendo √°reas relevantes.")
    elif prof_score >= 3:
        comments.append("El perfil presenta una buena alineaci√≥n con las expectativas del cargo, aunque hay margen de mejora. Podr√≠as enfocar tus esfuerzos en reforzar √°reas espec√≠ficas relacionadas con las competencias clave del puesto.")
    else:
        comments.append("Tu perfil necesita mejoras para alinearse mejor con las expectativas del cargo. Trabaja en desarrollar habilidades y competencias clave.")

    if round_overall_score >= 4:
        comments.append("La presentaci√≥n de tu hoja de vida es excelente. Refleja profesionalismo y claridad. Contin√∫a aplicando este enfoque para mantener un alto est√°ndar.")
    elif round_overall_score >= 3:
        comments.append("La presentaci√≥n de tu hoja de vida es buena, pero puede mejorar en aspectos como coherencia, ortograf√≠a o formato general. Dedica tiempo a revisar estos detalles.")
    else:
        comments.append("La presentaci√≥n de tu hoja de vida necesita mejoras significativas. Aseg√∫rate de revisar la ortograf√≠a, la gram√°tica y la coherencia para proyectar una imagen m√°s profesional.")

    if total_score >= 4:
        comments.append("Tu puntaje total indica un desempe√±o destacado en la mayor√≠a de las √°reas. Est√°s bien posicionado para asumir el rol. Mant√©n este nivel y busca perfeccionar tus fortalezas.")
    elif total_score >= 3:
        comments.append("Tu puntaje total es s√≥lido, pero hay aspectos que podr√≠an mejorarse. Enf√≥cate en perfeccionar la presentaci√≥n y el perfil para complementar tus fortalezas en experiencia, eventos y asistencia.")
    else:
        comments.append("El puntaje total muestra √°reas importantes por mejorar. Trabaja en fortalecer cada criterio para presentar un perfil m√°s competitivo y completo.")

    # A√±adir comentarios al reporte
    elements.append(Paragraph("<b>Comentarios sobre los Resultados:</b>", styles['CenturyGothicBold']))
    elements.append(Spacer(1, 0.2 * inch))
    for comment in comments:
        elements.append(Paragraph(comment, styles['CenturyGothic']))
        elements.append(Spacer(1, 0.1 * inch))

    elements.append(Spacer(1, 0.1 * inch))

    # Conclusi√≥n
    elements.append(Paragraph(
        f"Este an√°lisis es generado debido a que es crucial tomar medidas estrat√©gicas para garantizar que  los candidatos est√©n bien preparados para el rol de {position}. Los aspirantes con alta concordancia deben ser considerados seriamente para el cargo, ya que est√°n en una posici√≥n favorable para asumir responsabilidades significativas y contribuir al √©xito del Cap√≠tulo. Aquellos con buena concordancia deber√≠an continuar desarrollando su experiencia, mientras que los aspirantes con  baja concordancia deber√≠an recibir orientaci√≥n para mejorar su perfil profesional y acumular m√°s  experiencia relevante. Estas acciones asegurar√°n que el proceso de selecci√≥n se base en una evaluaci√≥n completa y precisa de las capacidades de cada candidato, fortaleciendo la gesti√≥n y el  impacto del Cap√≠tulo.",
        styles['CenturyGothic']
    ))

    elements.append(Spacer(1, 0.2 * inch))

    # Mensaje de agradecimiento
    elements.append(Paragraph(
        f"Gracias, {candidate_name}, por tu inter√©s en el cargo de {position} ¬°√âxitos en tu proceso!",
        styles['CenturyGothic']
    ))

    # Construcci√≥n del PDF
    doc.build(elements, onFirstPage=on_first_page, onLaterPages=on_later_pages)

    # Read the PDF file as bytes
    with open(output_path, "rb") as pdf_file:
        pdf_bytes = pdf_file.read()
    # Encode PDF bytes to base64 string
    pdf_base64_string = base64.b64encode(pdf_bytes).decode('utf-8')

    return pdf_base64_string, output_path # Return base64 string and report path

def calculate_indicators_for_report_gemini(lines, position, indicator_descriptions): # A√±adir indicator_descriptions
    """
    Calcula los porcentajes de relevancia de indicadores para el reporte usando Gemini.
    :param lines: Lista de l√≠neas de la secci√≥n relevante del CV.
    :param position: Cargo al que aspira (para obtener las descripciones de indicadores).
    :param indicator_descriptions: Diccionario con descripciones de indicadores para el cargo.
    :return: Diccionario con los porcentajes por indicador y detalles de l√≠neas relevantes.
    """
    indicator_results = {}
    for indicator, description_list in indicator_descriptions.items(): # Iterar sobre descriptions
        if description_list: # Asegurarse de que la lista de descripciones no est√© vac√≠a
            indicator_description = description_list[0] # Tomar la primera descripci√≥n como ejemplo (puedes ajustarlo)
        else:
            print(f"‚ö†Ô∏è No se encontr√≥ descripci√≥n para el indicador '{indicator}' en advice.json para el cargo '{position}'.")
            indicator_description = f"Indicador: {indicator}." # Descripci√≥n gen√©rica si no se encuentra

        relevant_lines_count = 0
        for line in lines:
            if is_relevant_for_indicator_gemini(line, indicator_description, indicator=indicator, position=position): # Pasar indicator e position
                relevant_lines_count += 1

        total_lines = len(lines)
        percentage = (relevant_lines_count / total_lines) * 100 if total_lines > 0 else 0
        indicator_results[indicator] = {"percentage": percentage, "relevant_lines": relevant_lines_count}
    return indicator_results


def is_relevant_for_indicator_gemini(line, indicator_description, indicator, position): # A√±adir indicator y position
    """
    Determina si una l√≠nea de texto es sem√°nticamente relevante para un indicador usando Gemini.
    :param line: L√≠nea de texto del CV a evaluar.
    :param indicator_description: Descripci√≥n del indicador (desde advice.json).
    :param indicator: Nombre del indicador (para debugging).
    :param position: Cargo (para debugging).
    """
    if not line or not indicator_description:
        return False

    try:
        model = genai.GenerativeModel(MODELO_GEMINI)
        prompt = f"""
            Instrucciones: Eres un evaluador de hojas de vida. Determina si la siguiente l√≠nea de texto de una hoja de vida es **relevante** para el siguiente indicador, bas√°ndote en su descripci√≥n. Responde **'S√≠'** o **'No'** solamente.

            Cargo del candidato: {position}
            Indicador a evaluar: {indicator}
            Descripci√≥n del indicador: {indicator_description}

            L√≠nea de texto de la hoja de vida:
            {line}

            ¬øEs relevante la l√≠nea de texto para el indicador? (Responde 'S√≠' o 'No'):
            """
        response = model.generate_content([prompt])
        respuesta_texto = response.text.strip().lower()
        return "s√≠" in respuesta_texto or "yes" in respuesta_texto

    except Exception as e:
        print(f"‚ö†Ô∏è Error al usar Gemini para is_relevant_for_indicator_gemini (Indicador: {indicator}, Cargo: {position}): {e}")
        return False


def generate_report_with_background_api(pdf_path, position, candidate_name,background_path, chapter):
    """
    Genera un reporte con un fondo en cada p√°gina for API usage, returns base64 encoded PDF.
    :param pdf_path: Ruta del PDF.
    :param position: Cargo al que aspira.
    :param candidate_name: Nombre del candidato.
    :param background_path: Ruta de la imagen de fondo.
    :param chapter: Cap√≠tulo del Candidato
    :return: base64 encoded PDF content and report path
    """
    experience_text = extract_experience_section_with_ocr(pdf_path)
    if not experience_text:
        return None, "No se encontr√≥ la secci√≥n 'EXPERIENCIA EN ANEIAP' en el PDF."

    org_text = extract_event_section_with_ocr(pdf_path)
    if not org_text:
        return None, "No se encontr√≥ la secci√≥n 'EVENTOS ORGANIZADOS' en el PDF."

    att_text = extract_attendance_section_with_ocr(pdf_path)
    if not att_text:
        return None, "No se encontr√≥ la secci√≥n 'Asistencia a Eventos ANEIAP' en el PDF."

    resume_text= evaluate_cv_presentation(pdf_path)
    if not resume_text:
        return None, "No se encontr√≥ el texto de la hoja de vida"

    candidate_profile_text= extract_profile_section_with_ocr(pdf_path)
    if not candidate_profile_text:
        return None, "No se encontr√≥ la secci√≥n 'Perfil' en el PDF."

    # Dividir la experiencia en l√≠neas
    lines = extract_cleaned_lines(experience_text)
    lines= experience_text.split("\n")
    lines = [line.strip() for line in lines if line.strip()]  # Eliminar l√≠neas vac√≠as

    # Dividir los eventos en l√≠neas
    org_lines = extract_cleaned_lines(org_text)
    org_lines= org_text.split("\n")
    org_lines = [line.strip() for line in org_lines if line.strip()]  # Eliminar l√≠neas vac√≠as

    #Dividir lineas de perfil
    candidate_profile_lines = extract_cleaned_lines(candidate_profile_text)
    candidate_profile_lines= candidate_profile_text.split("\n")
    candidate_profile_lines= [line.strip() for line in candidate_profile_lines if line.strip()]

    # Dividir la asistencia en l√≠neas
    att_lines = extract_cleaned_lines(att_text)
    att_lines= att_text.split("\n")
    att_lines = [line.strip() for line in att_lines if line.strip()]  # Eliminar l√≠neas vac√≠as

    # Obtener los indicadores y palabras clave para el cargo seleccionado
    position_indicators = indicators.get(position, {})
    position_advice = advice.get(position, {}) # Cargar advice para el cargo

    #indicator_results = calculate_all_indicators(lines, position_indicators) #REEMPLAZAR POR VERSION GEMINI
    indicator_results = calculate_indicators_for_report_gemini(lines, position, position_advice) # Usar funci√≥n Gemini para indicadores

    # Cargar funciones y perfil
    try:
        with fitz.open(f"Funciones//F{position}.pdf") as func_doc:
            functions_text = func_doc[0].get_text()
        with fitz.open(f"Perfiles/P{position}.pdf") as profile_doc:
            profile_text = profile_doc[0].get_text()
    except Exception as e:
        return None, f"Error al cargar funciones o perfil: {e}"

    line_results = []
    org_line_results = []
    att_line_results = []

    # Evaluaci√≥n de renglones de EXPERIENCIA EN ANEIAP
    # Evaluaci√≥n de renglones
    for line in lines:
        line = line.strip()
        if not line:  # Ignorar l√≠neas vac√≠as
            continue

        # Dividir la experiencia en l√≠neas
        lines = extract_cleaned_lines(experience_text)
        lines = experience_text.split("\n")
        lines = [line.strip() for line in lines if line.strip()]  # Eliminar l√≠neas vac√≠as

        # Obtener los indicadores y palabras clave para el cargo seleccionado
        position_indicators = indicators.get(position, {})
        indicator_results = {}

        # Calcular el porcentaje por cada indicador
        indicator_results = calculate_indicators_for_report(lines, position_indicators)
        for indicator, keywords in position_indicators.items():
            indicator_results = calculate_indicators_for_report(lines, position_indicators)

        # Calcular la presencia total (si es necesario)
        total_presence = sum(result["percentage"] for result in indicator_results.values())

        # Normalizar los porcentajes si es necesario
        if total_presence > 0:
            for indicator in indicator_results:
                indicator_results[indicator]["percentage"] = (indicator_results[indicator]["percentage"] / total_presence) * 100

        # Evaluaci√≥n general de concordancia
        if any(keyword.lower() in line.lower() for kw_set in position_indicators.values() for keyword in kw_set):
            func_match = 100.0
            profile_match = 100.0
        else:
            # Calcular similitud
            func_match = calculate_similarity(line, functions_text)
            profile_match = calculate_similarity(line, profile_text)

        # Solo agregar al reporte si no tiene 0% en ambas m√©tricas
        if func_match > 0 or profile_match > 0:
            line_results.append((line, func_match, profile_match))

    # Normalizaci√≥n de los resultados de indicadores
    total_presence = sum(indicator["percentage"] for indicator in indicator_results.values())
    if total_presence > 0:
        for indicator in indicator_results:
            indicator_results[indicator]["percentage"] = (indicator_results[indicator]["percentage"] / total_presence) * 100

    # Evaluaci√≥n de renglones eventos organizados
    for line in org_lines:
        line = line.strip()
        if not line:  # Ignorar l√≠neas vac√≠as
            continue

        # Dividir los eventos en l√≠neas
        org_lines = extract_cleaned_lines(org_text)
        org_lines= att_text.split("\n")
        org_lines = [line.strip() for line in org_lines if line.strip]

        # Evaluaci√≥n general de concordancia
        if any(keyword.lower() in line.lower() for kw_set in position_indicators.values() for keyword in kw_set):
            org_func_match = 100.0
            org_profile_match = 100.0
        else:
            # Calcular similitud
            org_func_match = calculate_similarity(line, functions_text)
            org_profile_match = calculate_similarity(line, profile_text)

        # Solo agregar al reporte si no tiene 0% en ambas m√©tricas
        if org_func_match > 0 or org_profile_match > 0:
            org_line_results.append((line, org_func_match, org_profile_match))

    # Evaluaci√≥n de renglones asistencia a eventos
    for line in att_lines:
        line = line.strip()
        if not line:  # Ignorar l√≠neas vac√≠as
            continue

        # Dividir los asistencia en l√≠neas
        att_lines = extract_cleaned_lines(att_text)
        att_lines= att_text.split("\n")
        att_lines = [line.strip() for line in att_lines if line.strip]

        # Evaluaci√≥n general de concordancia
        if any(keyword.lower() in line.lower() for kw_set in position_indicators.values() for keyword in kw_set):
            att_func_match = 100.0
            att_profile_match = 100.0
        else:
            # Calcular similitud
            att_func_match = calculate_similarity(line, functions_text)
            att_profile_match = calculate_similarity(line, profile_text)

        # Solo agregar al reporte si no tiene 0% en ambas m√©tricas
        if att_func_match > 0 or att_profile_match > 0:
            att_line_results.append((line, att_func_match, att_profile_match))

    # Calcular porcentajes de concordancia con perfil de candidato
    keyword_count = 0
    words = re.findall(r"\b\w+\b", candidate_profile_text)
    total_words = len(words)
    for kw_set in position_indicators.values():
        for keyword in kw_set:
            keyword_count += candidate_profile_text.count(keyword)

    prop_keyword= keyword_count/total_words

    # Evitar divisi√≥n por cero
    if prop_keyword<= 0.01:
        keyword_match_percentage = 0
    elif 0.01 <prop_keyword <= 0.15:
        keyword_match_percentage = 25
    elif 0.15 <prop_keyword <= 0.5:
        keyword_match_percentage = 50
    elif 0.5 <prop_keyword <= 0.75:
        keyword_match_percentage = 75
    else:
        keyword_match_percentage = 100

    # Evaluaci√≥n de concordancia basada en palabras clave
    if keyword_match_percentage == 100:
        profile_func_match = 100.0
        profile_profile_match = 100.0
    else:
        # Calcular similitud con funciones y perfil del cargo si la coincidencia es baja
        prof_func_match = calculate_similarity(candidate_profile_text, functions_text)
        prof_profile_match = calculate_similarity(candidate_profile_text, profile_text)
        profile_func_match = keyword_match_percentage + prof_func_match
        profile_profile_match = keyword_match_percentage + prof_profile_match

    # Calcular porcentajes parciales respecto a la Experiencia ANEIAP
    if line_results:  # Evitar divisi√≥n por cero si no hay √≠tems v√°lidos
        parcial_exp_func_match = sum([res[1] for res in line_results]) / len(line_results)
        parcial_exp_profile_match = sum([res[2] for res in line_results]) / len(line_results)
    else:
        parcial_exp_func_match = 0
        parcial_exp_profile_match = 0

    # Calcular porcentajes parciales respecto a los Eventos ANEIAP
    if org_line_results:  # Evitar divisi√≥n por cero si no hay √≠tems v√°lidos
        parcial_org_func_match = sum([res[1] for res in org_line_results]) / len(org_line_results)
        parcial_org_profile_match = sum([res[2] for res in org_line_results]) / len(org_line_results)
    else:
        parcial_org_func_match = 0
        parcial_org_profile_match = 0

    # Calcular porcentajes parciales respecto a la asistencia a eventos
    if att_line_results:  # Evitar divisi√≥n por cero si no hay √≠tems v√°lidos
        parcial_att_func_match = sum([res[1] for res in att_line_results]) / len(att_line_results)
        parcial_att_profile_match = sum([res[2] for res in att_line_results]) / len(att_line_results)
    else:
        parcial_att_func_match = 0
        parcial_att_profile_match = 0

    resume_text= evaluate_cv_presentation(pdf_path)

    # Inicializar corrector ortogr√°fico
    spell = SpellChecker(language='es')

    punctuation_errors = 0

    for i, line in enumerate(lines):
        # Verificar si la oraci√≥n termina con puntuaci√≥n v√°lida
        if not line.endswith((".", "!", "?")):
            punctuation_errors += 1

    # Limpiar y dividir el texto en l√≠neas
    pres_cleaned_lines = [line.strip() for line in resume_text.split("\n") if line.strip()]
    total_lines = len(pres_cleaned_lines)

    # M√©tricas
    total_words = 0
    spelling_errors = 0
    missing_capitalization = 0
    incomplete_sentences = 0
    punctuation_marks = 0
    grammar_errors = 0

    for line in pres_cleaned_lines:
        # Dividir en palabras y contar
        words = re.findall(r'\b\w+\b', line)
        total_words += len(words)

        # Ortograf√≠a
        misspelled = spell.unknown(words)
        spelling_errors += len(misspelled)

        # Verificar capitalizaci√≥n
        if line and not line[0].isupper():
            missing_capitalization += 1

        # Verificar que termine en signo de puntuaci√≥n
        if not line.endswith((".", "!", "?", ":", ";")):
            incomplete_sentences += 1

        # Gram√°tica b√°sica: verificar patrones comunes (ejemplo)
        grammar_errors += len(re.findall(r'\b(?:es|est√°|son)\b [^\w\s]', line))  # Ejemplo: "es" sin continuaci√≥n v√°lida

    # Calcular m√©tricas secundarias
    spelling = 1- (spelling_errors / total_words)
    capitalization_score = 1- (missing_capitalization / total_lines)
    sentence_completion_score = 1- (incomplete_sentences / total_lines)
    grammar = 1- (grammar_errors / total_lines)
    punctuation_error_rate = 1- (punctuation_errors / total_lines)

    #Calcular m√©tricas principales
    grammar_score = round(((punctuation_error_rate+ grammar+ sentence_completion_score)/3)*5, 2)
    spelling_score= round(((spelling+ capitalization_score)/2)*5,2)

    if total_lines == 0:
        return 100  # Si no hay oraciones, asumimos coherencia perfecta.

    # Calcular m√©tricas coherencia
    # 1. Repetici√≥n de palabras
    def calculate_word_repetition(pres_cleaned_lines):
        repeated_words = Counter()
        for line in pres_cleaned_lines:
            words = line.split()
            repeated_words.update([word.lower() for word in words])

        total_words = sum(repeated_words.values())
        unique_words = len(repeated_words)
        most_common_word_count = repeated_words.most_common(1)[0][1] if repeated_words else 0
        repeated_word_ratio = (most_common_word_count / total_words) if total_words > 0 else 0

        # Una menor repetici√≥n indica mayor calidad
        repetition_score = 1 - repeated_word_ratio
        return repetition_score, repeated_words

    # 2. Fluidez entre oraciones
    def calculate_sentence_fluency(pres_cleaned_lines):
        """
        Calcula el puntaje de fluidez de las oraciones bas√°ndose en conectores l√≥gicos, puntuaci√≥n,
        y variabilidad en la longitud de las oraciones.
        :param pres_cleaned_lines: Lista de l√≠neas limpias del texto.
        :return: Puntaje de fluidez de las oraciones entre 0 y 1.
        """
        # Lista de conectores l√≥gicos comunes
        logical_connectors = {
        "adici√≥n": [
            "adem√°s", "tambi√©n", "asimismo", "igualmente", "de igual manera",
            "por otro lado", "de la misma forma", "junto con"
        ],
        "causa": [
            "porque", "ya que", "debido a", "dado que", "por motivo de",
            "gracias a", "en raz√≥n de", "a causa de"
        ],
        "consecuencia": [
            "por lo tanto", "as√≠ que", "en consecuencia", "como resultado",
            "por esta raz√≥n", "de modo que", "lo que permiti√≥", "de ah√≠ que"
        ],
        "contraste": [
            "sin embargo", "pero", "aunque", "no obstante", "a pesar de",
            "por el contrario", "en cambio", "si bien", "mientras que"
        ],
        "condici√≥n": [
            "si", "en caso de", "a menos que", "siempre que", "con la condici√≥n de",
            "a no ser que", "en el supuesto de que"
        ],
        "tiempo": [
            "mientras", "cuando", "despu√©s de", "antes de", "al mismo tiempo",
            "posteriormente", "una vez que", "simult√°neamente", "en el transcurso de"
        ],
        "descripci√≥n de funciones": [
            "encargado de", "responsable de", "mis funciones inclu√≠an",
            "lider√©", "gestion√©", "coordin√©", "dirig√≠", "supervis√©",
            "desarroll√©", "planifiqu√©", "ejecut√©", "implement√©", "organic√©"
        ],
        "logros y resultados": [
            "logr√©", "alcanc√©", "consegu√≠", "increment√©", "reduje",
            "optimiz√©", "mejor√©", "aument√©", "potenci√©", "maximic√©",
            "contribu√≠ a", "obtuve", "permiti√≥ mejorar", "impact√≥ positivamente en"
        ],
        "secuencia": [
            "primero", "en primer lugar", "a continuaci√≥n", "luego", "despu√©s",
            "seguidamente", "posteriormente", "finalmente", "por √∫ltimo"
        ],
        "√©nfasis": [
            "sobre todo", "en particular", "especialmente", "principalmente",
            "espec√≠ficamente", "vale la pena destacar", "conviene resaltar",
            "cabe mencionar", "es importante se√±alar"
        ],
        "conclusi√≥n": [
            "en resumen", "para concluir", "en definitiva", "en s√≠ntesis",
            "como conclusi√≥n", "por ende", "por consiguiente", "para finalizar"
        ]
    }
        connector_count = 0
        total_lines = len(pres_cleaned_lines)

        # Validaci√≥n para evitar divisiones por cero
        if total_lines == 0:
            return 0  # Sin l√≠neas, no se puede calcular fluidez

        # Inicializaci√≥n de m√©tricas
        punctuation_errors = 0
        sentence_lengths = []

        for line in pres_cleaned_lines:
            # Verificar errores de puntuaci√≥n (oraciones sin punto final)
            if not line.endswith((".", "!", "?")):
                punctuation_errors += 1

            # Almacenar la longitud de cada oraci√≥n
            sentence_lengths.append(len(line.split()))

            # Contar conectores l√≥gicos en la l√≠nea
            for connector in logical_connectors:
                if connector in line.lower():
                    connector_count += 1

        # Calcular m√©tricas individuales
        avg_length = sum(sentence_lengths) / total_lines
        length_variance = sum(
            (len(line.split()) - avg_length) ** 2 for line in pres_cleaned_lines
        ) / total_lines if total_lines > 1 else 0

        # Normalizar m√©tricas entre 0 y 1
        punctuation_score = max(0, 1 - (punctuation_errors / total_lines))  # 1 si no hay errores
        connector_score = min(1, connector_count / total_lines)  # M√°ximo 1, basado en conectores
        variance_penalty = max(0, 1 - length_variance / avg_length) if avg_length > 0 else 0

        # Calcular puntaje final de fluidez
        fluency_score = (punctuation_score + connector_score + variance_penalty) / 3
        return round(fluency_score, 2)


    # Calcular m√©tricas individuales
    repetition_score, repeated_words = calculate_word_repetition(pres_cleaned_lines)
    fluency_score = calculate_sentence_fluency(pres_cleaned_lines)

    # Asegurar que repetition_score y fluency_score est√°n entre 0 y 1 antes de la conversi√≥n
    normalized_repetition_score = min(1, max(0, repetition_score))
    normalized_fluency_score = min(1, max(0, fluency_score))

    # Calcular coherencia asegurando que el resultado final no pase de 5
    coherence_score = round(min(5, (normalized_repetition_score + normalized_fluency_score) * 2.5), 2)

    # Puntaje general ponderado
    overall_score = round((spelling_score  + coherence_score + grammar_score) / 3, 2)

    # Calculo puntajes parciales
    parcial_exp_func_score = round((parcial_exp_func_match * 5) / 100, 2)
    parcial_exp_profile_score = round((parcial_exp_profile_match * 5) / 100, 2)
    parcial_org_func_score = round((parcial_org_func_match * 5) / 100, 2)
    parcial_org_profile_score = round((parcial_org_profile_match * 5) / 100, 2)
    parcial_att_func_score = round((parcial_att_func_match * 5) / 100, 2)
    parcial_att_profile_score = round((parcial_att_profile_match * 5) / 100, 2)
    profile_func_score= round((profile_func_match * 5) / 100, 2)
    profile_profile_score= round((profile_profile_match * 5) / 100, 2)

    #Calcular resultados globales
    global_func_match = (parcial_exp_func_match + parcial_att_func_match + parcial_org_func_match+ profile_func_match) / 4
    global_profile_match = (parcial_exp_profile_match + parcial_att_profile_match + parcial_org_profile_match + profile_profile_match) / 4
    func_score = round((global_func_match * 5) / 100, 2)
    profile_score = round((global_profile_match * 5) / 100, 2)

    #Calculo puntajes totales
    exp_score= (parcial_exp_func_score+ parcial_exp_profile_score)/2
    org_score= (parcial_org_func_score+ parcial_org_profile_score)/2
    att_score= (parcial_att_func_score+ parcial_att_profile_score)/2
    prof_score= (profile_func_score+ profile_profile_score)/2
    total_score= (overall_score+ exp_score+ org_score+ att_score+ profile_score)/5

    # Registrar la fuente personalizada
    pdfmetrics.registerFont(TTFont('CenturyGothic', 'Century_Gothic.ttf'))
    pdfmetrics.registerFont(TTFont('CenturyGothicBold', 'Century_Gothic_Bold.ttf'))

    # Estilos
    styles = getSampleStyleSheet()
    styles.add(ParagraphStyle(name="CenturyGothic", fontName="CenturyGothic", fontSize=12, leading=14, alignment=TA_JUSTIFY))
    styles.add(ParagraphStyle(name="CenturyGothicBold", fontName="CenturyGothicBold", fontSize=12, leading=14, alignment=TA_JUSTIFY))

    # Crear el documento PDF
    report_path = f"Reporte_analisis_cargo_{candidate_name}_{position}_{chapter}.pdf"
    doc = SimpleDocTemplate(report_path, pagesize=letter, rightMargin=72, leftMargin=72, topMargin=100, bottomMargin=72)

    # Lista de elementos para el reporte
    elements = []

    # üìå **3Ô∏è‚É£ AGREGAR PORTADA SIN FONDO**
    def on_first_page(canvas, doc):
        """Dibuja una portada que ocupa toda la p√°gina."""
        draw_full_page_cover(canvas, portada_path, candidate_name, position, chapter)

    # T√≠tulo del reporte centrado
    title_style = ParagraphStyle(name='CenteredTitle', fontName='CenturyGothicBold', fontSize=14, leading=16, alignment=1,  # 1 significa centrado, textColor=colors.black
                                )
    # Convertir texto a may√∫sculas
    elements.append(PageBreak())
    title_candidate_name = candidate_name.upper()
    title_position = position.upper()
    tittle_chapter= chapter.upper()

    elements.append(Paragraph(f"REPORTE DE AN√ÅLISIS {title_candidate_name} CARGO {title_position} {tittle_chapter}", title_style))

    elements.append(Spacer(1, 0.2 * inch))

    # Concordancia de items organizada en tabla con ajuste de texto
    elements.append(Paragraph("<b>An√°lisis de perfil de aspirante:</b>", styles['CenturyGothicBold']))
    elements.append(Spacer(1, 0.2 * inch))

    # Encabezados de la tabla
    prof_table_data = [["√çtem", "Funciones del Cargo (%)", "Perfil del Cargo (%)"]]

    #Agregar resultados parciales
    prof_table_data.append([Paragraph("<b>Concordancia Parcial</b>", styles['CenturyGothicBold']), f"{profile_func_match:.2f}%", f"{profile_profile_match:.2f}%"])
    prof_table_data.append([Paragraph("<b>Puntaje Parcial</b>", styles['CenturyGothicBold']), f"{profile_func_score:.2f}", f"{profile_profile_score:.2f}"])

    # Crear la tabla con ancho de columnas ajustado
    prof_item_table = Table(prof_table_data, colWidths=[3 * inch, 2 * inch, 2 * inch])

    # Estilos de la tabla con ajuste de texto
    prof_item_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor("#F0F0F0")),  # Fondo para encabezados
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),  # Color de texto en encabezados
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),  # Alinear texto al centro
        ('FONTNAME', (0, 0), (-1, 0), 'CenturyGothicBold'),  # Fuente para encabezados
        ('FONTNAME', (0, 1), (-1, -1), 'CenturyGothic'),  # Fuente para el resto de la tabla
        ('FONTSIZE', (0, 0), (-1, -1), 10),  # Tama√±o de fuente
        ('BOTTOMPADDING', (0, 0), (-1, 0), 8),  # Padding inferior para encabezados
        ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),  # L√≠neas de la tabla
        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),  # Alinear texto verticalmente al centro
        ('WORDWRAP', (0, 0), (-1, -1)),  # Habilitar ajuste de texto
    ]))

    # Agregar tabla a los elementos
    elements.append(prof_item_table)

    elements.append(Spacer(1, 0.2 * inch))

    # Concordancia de items organizada en tabla con ajuste de texto
    elements.append(Paragraph("<b>An√°lisis de √≠tems de asistencia a eventos:</b>", styles['CenturyGothicBold']))
    elements.append(Spacer(1, 0.2 * inch))

    # Encabezados de la tabla
    att_table_data = [["√çtem", "Funciones del Cargo (%)", "Perfil del Cargo (%)"]]

    # Agregar datos de line_results a la tabla
    for line, att_func_match, att_profile_match in att_line_results:
        att_table_data.append([Paragraph(line, styles['CenturyGothic']), f"{att_func_match:.2f}%", f"{att_profile_match:.2f}%"])

    #Agregar resultados parciales
    att_table_data.append([Paragraph("<b>Concordancia Parcial</b>", styles['CenturyGothicBold']), f"{parcial_att_func_match:.2f}%", f"{parcial_att_profile_match:.2f}%"])
    att_table_data.append([Paragraph("<b>Puntaje Parcial</b>", styles['CenturyGothicBold']), f"{parcial_att_func_score:.2f}", f"{parcial_att_profile_score:.2f}"])

    # Crear la tabla con ancho de columnas ajustado
    att_item_table = Table(att_table_data, colWidths=[3 * inch, 2 * inch, 2 * inch])

    # Estilos de la tabla con ajuste de texto
    att_item_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor("#F0F0F0")),  # Fondo para encabezados
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),  # Color de texto en encabezados
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),  # Alinear texto al centro
        ('FONTNAME', (0, 0), (-1, 0), 'CenturyGothicBold'),  # Fuente para encabezados
        ('FONTNAME', (0, 1), (-1, -1), 'CenturyGothic'),  # Fuente para el resto de la tabla
        ('FONTSIZE', (0, 0), (-1, -1), 10),  # Tama√±o de fuente
        ('BOTTOMPADDING', (0, 0), (-1, 0), 8),  # Padding inferior para encabezados
        ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),  # L√≠neas de la tabla
        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),  # Alinear texto verticalmente al centro
        ('WORDWRAP', (0, 0), (-1, -1)),  # Habilitar ajuste de texto
    ]))

    # Agregar tabla a los elementos
    elements.append(att_item_table)

    elements.append(Spacer(1, 0.1 * inch))

    # Total de l√≠neas analizadas en ASISTENCIA A EVENTOS ANEIAP
    att_total_lines = len(att_line_results)
    elements.append(Paragraph(f"‚Ä¢ Total de asistencias a eventos analizadas: {att_total_lines}", styles['CenturyGothicBold']))

    elements.append(Spacer(1, 0.2 * inch))

    # Concordancia de items organizada en tabla con ajuste de texto
    elements.append(Paragraph("<b>An√°lisis de √≠tems de eventos organizados:</b>", styles['CenturyGothicBold']))
    elements.append(Spacer(1, 0.2 * inch))

    # Encabezados de la tabla
    org_table_data = [["√çtem", "Funciones del Cargo (%)", "Perfil del Cargo (%)"]]

    # Agregar datos de line_results a la tabla
    for line, org_func_match, org_profile_match in org_line_results:
        org_table_data.append([Paragraph(line, styles['CenturyGothic']), f"{org_func_match:.2f}%", f"{org_profile_match:.2f}%"])

    #Agregar resultados parciales
    org_table_data.append([Paragraph("<b>Concordancia Parcial</b>", styles['CenturyGothicBold']), f"{parcial_org_func_match:.2f}%", f"{parcial_org_profile_match:.2f}%"])
    org_table_data.append([Paragraph("<b>Puntaje Parcial</b>", styles['CenturyGothicBold']), f"{parcial_org_func_score:.2f}", f"{parcial_org_profile_score:.2f}"])

    # Crear la tabla con ancho de columnas ajustado
    org_item_table = Table(org_table_data, colWidths=[3 * inch, 2 * inch, 2 * inch])

    # Estilos de la tabla con ajuste de texto
    org_item_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor("#F0F0F0")),  # Fondo para encabezados
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),  # Color de texto en encabezados
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),  # Alinear texto al centro
        ('FONTNAME', (0, 0), (-1, 0), 'CenturyGothicBold'),  # Fuente para encabezados
        ('FONTNAME', (0, 1), (-1, -1), 'CenturyGothic'),  # Fuente para el resto de la tabla
        ('FONTSIZE', (0, 0), (-1, -1), 10),  # Tama√±o de fuente
        ('BOTTOMPADDING', (0, 0), (-1, 0), 8),  # Padding inferior para encabezados
        ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),  # L√≠neas de la tabla
        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),  # Alinear texto verticalmente al centro
        ('WORDWRAP', (0, 0), (-1, -1)),  # Habilitar ajuste de texto
    ]))

    # Agregar tabla a los elementos
    elements.append(org_item_table)

    elements.append(Spacer(1, 0.1 * inch))

    # Total de l√≠neas analizadas en ASISTENCIA A EVENTOS ANEIAP
    org_total_lines = len(org_line_results)
    elements.append(Paragraph(f"‚Ä¢ Total de eventos analizados: {org_total_lines}", styles['CenturyGothicBold']))

    elements.append(Spacer(1, 0.2 * inch))

    # Concordancia de items organizada en tabla con ajuste de texto
    elements.append(Paragraph("<b>An√°lisis de √≠tems:</b>", styles['CenturyGothicBold']))
    elements.append(Spacer(1, 0.2 * inch))

    # Encabezados de la tabla
    table_data = [["√çtem", "Funciones del Cargo (%)", "Perfil del Cargo (%)"]]

    # Agregar datos de line_results a la tabla
    for line, exp_func_match, exp_profile_match in line_results:
        table_data.append([Paragraph(line, styles['CenturyGothic']), f"{exp_func_match:.2f}%", f"{exp_profile_match:.2f}%"])

    #Agregar resultados parciales
    table_data.append([Paragraph("<b>Concordancia Parcial</b>", styles['CenturyGothicBold']), f"{parcial_exp_func_match:.2f}%", f"{parcial_exp_profile_match:.2f}%"])
    table_data.append([Paragraph("<b>Puntaje Parcial</b>", styles['CenturyGothicBold']), f"{parcial_exp_func_score:.2f}", f"{parcial_exp_profile_score:.2f}"])

    # Crear la tabla con ancho de columnas ajustado
    item_table = Table(table_data, colWidths=[3 * inch, 2 * inch, 2 * inch])

    # Estilos de la tabla con ajuste de texto
    item_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor("#F0F0F0")),  # Fondo para encabezados
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),  # Color de texto en encabezados
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),  # Alinear texto al centro
        ('FONTNAME', (0, 0), (-1, 0), 'CenturyGothicBold'),  # Fuente para encabezados
        ('FONTNAME', (0, 1), (-1, -1), 'CenturyGothic'),  # Fuente para el resto de la tabla
        ('FONTSIZE', (0, 0), (-1, -1), 10),  # Tama√±o de fuente
        ('BOTTOMPADDING', (0, 0), (-1, 0), 8),  # Padding inferior para encabezados
        ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),  # L√≠neas de la tabla
        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),  # Alinear texto verticalmente al centro
        ('WORDWRAP', (0, 0), (-1, -1)),  # Habilitar ajuste de texto
    ]))

    # Agregar tabla a los elementos
    elements.append(item_table)

    elements.append(Spacer(1, 0.2 * inch))

    # Total de l√≠neas analizadas en EXPERIENCIA EN ANEIAP
    total_lines = len(line_results)
    elements.append(Paragraph(f"‚Ä¢ Total de experiencias analizadas: {total_lines}", styles['CenturyGothicBold']))

    elements.append(Spacer(1, 0.2 * inch))

    # A√±adir resultados al reporte
    elements.append(Paragraph("<b>Evaluaci√≥n de la Presentaci√≥n:</b>", styles['CenturyGothicBold']))
    elements.append(Spacer(1, 0.2 * inch))

    # Crear tabla de evaluaci√≥n de presentaci√≥n
    presentation_table = Table(
        [
            ["Criterio", "Puntaje"],
            ["Coherencia", f"{coherence_score:.2f}"],
            ["Ortograf√≠a", f"{spelling_score:.2f}"],
            ["Gram√°tica", f"{grammar_score:.2f}"],
            ["Puntaje Total", f"{overall_score:.2f}"]
        ],
        colWidths=[3 * inch, 2 * inch]
    )

    # Estilo de la tabla
    presentation_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor("#F0F0F0")),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
        ('FONTNAME', (0, 0), (-1, 0), 'CenturyGothicBold'),
        ('FONTNAME', (0, 1), (-1, -1), 'CenturyGothic'),
        ('FONTSIZE', (0, 0), (-1, -1), 10),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 8),
        ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),
        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
    ]))

    elements.append(presentation_table)

    elements.append(Spacer(1, 0.2 * inch))

    elements.append(Paragraph("<b>Consejos para mejorar la presentaci√≥n de la hoja de vida:</b>", styles['CenturyGothicBold']))
    elements.append(Spacer(1, 0.2 * inch))

    elements.append(Spacer(1, 0.2 * inch))
    # Concordancia de items organizada en tabla con ajuste de texto
    elements.append(Paragraph("<b>Resultados de indicadores:</b>", styles['CenturyGothicBold']))
    elements.append(Spacer(1, 0.2 * inch))

    # Encabezados de la tabla
    table_indicator = [["Indicador", "Concordancia (%)"]]

    # Agregar datos de line_results a la tabla
    for indicator, data in indicator_results.items():
        relevant_lines = sum(
            any(keyword.lower() in line.lower() for keyword in keywords) for line in lines
        )
        total_lines = len(line_results)
        percentage = (relevant_lines / total_lines) * 100 if total_lines > 0 else 0
        if isinstance(percentage, (int, float)):  # Validar que sea un n√∫mero
            table_indicator.append([Paragraph(indicator, styles['CenturyGothic']), f"{percentage:.2f}%"])

    # Crear la tabla con ancho de columnas ajustado
    indicator_table = Table(table_indicator, colWidths=[3 * inch, 2 * inch, 2 * inch])

    # Estilos de la tabla con ajuste de texto
    indicator_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor("#F0F0F0")),  # Fondo para encabezados
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),  # Color de texto en encabezados
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),  # Alinear texto al centro
        ('FONTNAME', (0, 0), (-1, 0), 'CenturyGothicBold'),  # Fuente para encabezados
        ('FONTNAME', (0, 1), (-1, -1), 'CenturyGothic'),  # Fuente para el resto de la tabla
        ('FONTSIZE', (0, 0), (-1, -1), 10),  # Tama√±o de fuente
        ('BOTTOMPADDING', (0, 0), (-1, 0), 8),  # Padding inferior para encabezados
        ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),  # L√≠neas de la tabla
        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),  # Alinear texto verticalmente al centro
        ('WORDWRAP', (0, 0), (-1, -1)),  # Habilitar ajuste de texto
    ]))

    # Agregar tabla a los elementos
    elements.append(indicator_table)

    elements.append(Spacer(1, 0.2 * inch))

    # Consejos para mejorar indicadores con baja presencia
    low_performance_indicators = {k: v for k, v in indicator_results.items() if (relevant_lines/ total_lines) * 100 < 60.0}
    if low_performance_indicators:
        elements.append(Paragraph("<b>Consejos para Mejorar:</b>", styles['CenturyGothicBold']))
        elements.append(Spacer(1, 0.05 * inch))
        for indicator, result in low_performance_indicators.items():
            percentage = (relevant_lines/ total_lines)*100
            elements.append(Paragraph(f" {indicator}: ({percentage:.2f}%)", styles['CenturyGothicBold']))
            elements.append(Spacer(1, 0.05 * inch))
            for tip in advice[position].get(indicator, []):
                elements.append(Paragraph(f"  ‚Ä¢ {tip}", styles['CenturyGothic']))
                elements.append(Spacer(1, 0.1 * inch))

    elements.append(Spacer(1, 0.2 * inch))

   # Concordancia de items organizada en tabla global con ajuste de texto
    elements.append(Paragraph("<b>Resultados globales:</b>", styles['CenturyGothicBold']))

    elements.append(Spacer(1, 0.2 * inch))

    # Encabezados de la tabla global
    global_table_data = [["Criterio","Funciones del Cargo", "Perfil del Cargo"]]

    # Agregar datos de global_results a la tabla
    global_table_data.append([Paragraph("<b>Concordancia Global</b>", styles['CenturyGothicBold']), f"{global_func_match:.2f}%", f"{global_profile_match:.2f}%"])
    global_table_data.append([Paragraph("<b>Puntaje Global</b>", styles['CenturyGothicBold']), f"{func_score:.2f}", f"{profile_score:.2f}"])

    # Crear la tabla con ancho de columnas ajustado
    global_table = Table(global_table_data, colWidths=[3 * inch, 2 * inch, 2 * inch])

    # Estilos de la tabla con ajuste de texto
    global_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor("#F0F0F0")),  # Fondo para encabezados
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),  # Color de texto en encabezados
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),  # Alinear texto al centro
        ('FONTNAME', (0, 0), (-1, 0), 'CenturyGothicBold'),  # Fuente para encabezados
        ('FONTNAME', (0, 1), (-1, -1), 'CenturyGothic'),  # Fuente para el resto de la tabla
        ('FONTSIZE', (0, 0), (-1, -1), 10),  # Tama√±o de fuente
        ('BOTTOMPADDING', (0, 0), (-1, 0), 8),  # Padding inferior para encabezados
        ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),  # L√≠neas de la tabla
        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),  # Alinear texto verticalmente al centro
        ('WORDWRAP', (0, 0), (-1, -1)),  # Habilitar ajuste de texto
    ]))

    # Agregar tabla a los elementos
    elements.append(global_table)

    elements.append(Spacer(1, 0.2 * inch))

    # Interpretaci√≥n de resultados
    elements.append(Paragraph("<b>Interpretaci√≥n de resultados globales:</b>", styles['CenturyGothicBold']))
    elements.append(Spacer(1, 0.1 * inch))
    if global_profile_match > 75 and global_func_match > 75:
        elements.append(Paragraph(
            f" Alta Concordancia (> 0.75): El an√°lisis revela que {candidate_name} tiene una excelente adecuaci√≥n con las funciones del cargo de {position} y el perfil buscado. La experiencia detallada en su hoja de vida est√° estrechamente alineada con las responsabilidades y competencias requeridas para este rol crucial en la prevalencia del Cap√≠tulo. La alta concordancia indica que {candidate_name} est√° bien preparado para asumir este cargo y contribuir significativamente al √©xito y la misi√≥n del Cap√≠tulo. Se recomienda proceder con el proceso de selecci√≥n y considerar a {candidate_name} como una opci√≥n s√≥lida para el cargo.",
            styles['CenturyGothic']
        ))
    elif 60 < global_profile_match <= 75 or 60 < global_func_match <= 75:
        elements.append(Paragraph(
            f" Buena Concordancia (> 0.60): El an√°lisis muestra que {candidate_name} tiene una buena correspondencia con las funciones del cargo de {position} y el perfil deseado. Aunque su experiencia en la asociaci√≥n es relevante, existe margen para mejorar. {candidate_name} muestra potencial para cumplir con el rol crucial en la prevalencia del Cap√≠tulo, pero se recomienda que contin√∫e desarrollando sus habilidades y acumulando m√°s experiencia relacionada con el cargo objetivo. Su candidatura debe ser considerada con la recomendaci√≥n de enriquecimiento adicional.",
            styles['CenturyGothic']
        ))
    elif 60 < global_profile_match or 60 < global_func_match:
        elements.append(Paragraph(
            f" Baja Concordancia (< 0.60): El an√°lisis indica que {candidate_name} tiene una baja concordancia con los requisitos del cargo de {position} y el perfil buscado. Esto sugiere que aunque el aspirante posee algunas experiencias relevantes, su historial actual no cubre adecuadamente las competencias y responsabilidades necesarias para este rol crucial en la prevalencia del Cap√≠tulo. Se aconseja a {candidate_name} enfocarse en mejorar su perfil profesional y desarrollar las habilidades necesarias para el cargo. Este enfoque permitir√° a {candidate_name} alinear mejor su perfil con los requisitos del puesto en futuras oportunidades.",
            styles['CenturyGothic']
        ))

    elements.append(Spacer(1, 0.2 * inch))

    # A√±adir resultados al reporte
    elements.append(Paragraph("<b>Puntajes totales:</b>", styles['CenturyGothicBold']))
    elements.append(Spacer(1, 0.2 * inch))

    total_score= (exp_score+ att_score+ org_score+ round_overall_score+ profile_score)/5

    # Crear tabla de evaluaci√≥n de presentaci√≥n
    total_table = Table(
        [
            ["Criterio", "Puntaje"],
            ["Experiencia en ANEIAP", f"{exp_score:.2f}"],
            ["Asistencia a eventos", f"{att_score:.2f}"],
            ["Eventos organizados", f"{org_score:.2f}"],
            ["Perfil", f"{prof_score:.2f}"],
            ["Presentaci√≥n", f"{round_overall_score:.2f}"],
            ["Puntaje Total", f"{total_score:.2f}"]
        ],
        colWidths=[3 * inch, 2 * inch]
    )

    # Estilo de la tabla
    total_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor("#F0F0F0")),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
        ('FONTNAME', (0, 0), (-1, 0), 'CenturyGothicBold'),
        ('FONTNAME', (0, 1), (-1, -1), 'CenturyGothic'),
        ('FONTSIZE', (0, 0), (-1, -1), 10),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 8),
        ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),
        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
    ]))

    elements.append(total_table)

    elements.append(Spacer(1, 0.2 * inch))

    # Generar comentarios para los resultados
    comments = []

    if exp_score >= 4:
        comments.append("Tu experiencia en ANEIAP refleja un nivel destacado, lo que demuestra un conocimiento s√≥lido de la organizaci√≥n y tus contribuciones en actividades clave. Contin√∫a fortaleciendo tu participaci√≥n para mantener este nivel y destacar a√∫n m√°s.")
    elif exp_score >= 3:
        comments.append("Tu experiencia en ANEIAP es buena, pero podr√≠as enfocarte en profundizar tus contribuciones y participaci√≥n en actividades clave.")
    else:
        comments.append("Es importante fortalecer tu experiencia en ANEIAP. Considera involucrarte en m√°s actividades y proyectos para adquirir una mayor comprensi√≥n y relevancia.")

    if att_score >= 4:
        comments.append("Tu puntuaci√≥n en asistencia a eventos es excelente. Esto muestra tu compromiso con el aprendizaje y el desarrollo profesional. Mant√©n esta consistencia participando en eventos relevantes que sigan ampliando tu red de contactos y conocimientos.")
    elif att_score >= 3:
        comments.append("Tu asistencia a eventos es adecuada, pero hay margen para participar m√°s en actividades que refuercen tu aprendizaje y crecimiento profesional.")
    else:
        comments.append("Debes trabajar en tu participaci√≥n en eventos. La asistencia regular a actividades puede ayudarte a desarrollar habilidades clave y expandir tu red de contactos.")

    if org_score >= 4:
        comments.append("¬°Perfecto! Tu desempe√±o en la organizaci√≥n de eventos es ejemplar. Esto indica habilidades destacadas de planificaci√≥n, liderazgo y ejecuci√≥n. Considera compartir tus experiencias con otros miembros para fortalecer el impacto organizacional.")
    elif org_score >= 3:
        comments.append("Tu desempe√±o en la organizaci√≥n de eventos es bueno, pero podr√≠as centrarte en mejorar la planificaci√≥n y la ejecuci√≥n para alcanzar un nivel m√°s destacado.")
    else:
        comments.append("Es importante trabajar en tus habilidades de organizaci√≥n de eventos. Considera involucrarte en proyectos donde puedas asumir un rol de liderazgo y planificaci√≥n.")

    if prof_score >= 4:
        comments.append("Tu perfil presenta una buena alineaci√≥n con las expectativas del cargo, destacando competencias clave. Mant√©n este nivel y contin√∫a fortaleciendo √°reas relevantes.")
    elif prof_score >= 3:
        comments.append("El perfil presenta una buena alineaci√≥n con las expectativas del cargo, aunque hay margen de mejora. Podr√≠as enfocar tus esfuerzos en reforzar √°reas espec√≠ficas relacionadas con las competencias clave del puesto.")
    else:
        comments.append("Tu perfil necesita mejoras para alinearse mejor con las expectativas del cargo. Trabaja en desarrollar habilidades y competencias clave.")

    if round_overall_score >= 4:
        comments.append("La presentaci√≥n de tu hoja de vida es excelente. Refleja profesionalismo y claridad. Contin√∫a aplicando este enfoque para mantener un alto est√°ndar.")
    elif round_overall_score >= 3:
        comments.append("La presentaci√≥n de tu hoja de vida es buena, pero puede mejorar en aspectos como coherencia, ortograf√≠a o formato general. Dedica tiempo a revisar estos detalles.")
    else:
        comments.append("La presentaci√≥n de tu hoja de vida necesita mejoras significativas. Aseg√∫rate de revisar la ortograf√≠a, la gram√°tica y la coherencia para proyectar una imagen m√°s profesional.")

    if total_score >= 4:
        comments.append("Tu puntaje total indica un desempe√±o destacado en la mayor√≠a de las √°reas. Est√°s bien posicionado para asumir el rol. Mant√©n este nivel y busca perfeccionar tus fortalezas.")
    elif total_score >= 3:
        comments.append("Tu puntaje total es s√≥lido, pero hay aspectos que podr√≠an mejorarse. Enf√≥cate en perfeccionar la presentaci√≥n y el perfil para complementar tus fortalezas en experiencia, eventos y asistencia.")
    else:
        comments.append("El puntaje total muestra √°reas importantes por mejorar. Trabaja en fortalecer cada criterio para presentar un perfil m√°s competitivo y completo.")

    # A√±adir comentarios al reporte
    elements.append(Paragraph("<b>Comentarios sobre los Resultados:</b>", styles['CenturyGothicBold']))
    elements.append(Spacer(1, 0.2 * inch))
    for comment in comments:
        elements.append(Paragraph(comment, styles['CenturyGothic']))
        elements.append(Spacer(1, 0.1 * inch))

    elements.append(Spacer(1, 0.1 * inch))

    # Conclusi√≥n
    elements.append(Paragraph(
        f"Este an√°lisis es generado debido a que es crucial tomar medidas estrat√©gicas para garantizar que  los candidatos est√©n bien preparados para el rol de {position}. Los aspirantes con alta concordancia deben ser considerados seriamente para el cargo, ya que est√°n en una posici√≥n favorable para asumir responsabilidades significativas y contribuir al √©xito del Cap√≠tulo. Aquellos con buena concordancia deber√≠an continuar desarrollando su experiencia, mientras que los aspirantes con  baja concordancia deber√≠an recibir orientaci√≥n para mejorar su perfil profesional y acumular m√°s  experiencia relevante. Estas acciones asegurar√°n que el proceso de selecci√≥n se base en una evaluaci√≥n completa y precisa de las capacidades de cada candidato, fortaleciendo la gesti√≥n y el  impacto del Cap√≠tulo.",
        styles['CenturyGothic']
    ))

    elements.append(Spacer(1, 0.2 * inch))

    # Mensaje de agradecimiento
    elements.append(Paragraph(
        f"Gracias, {candidate_name}, por tu inter√©s en el cargo de {position} ¬°√âxitos en tu proceso!",
        styles['CenturyGothic']
    ))

    # Construcci√≥n del PDF
    doc.build(elements, onFirstPage=on_first_page, onLaterPages=on_later_pages)

    # Read the PDF file as bytes
    with open(output_path, "rb") as pdf_file:
        pdf_bytes = pdf_file.read()
    # Encode PDF bytes to base64 string
    pdf_base64_string = base64.b64encode(pdf_bytes).decode('utf-8')

    return pdf_base64_string, output_path # Return base64 string and report path


def analyze_and_generate_descriptive_report_with_background_api(pdf_path, position, candidate_name, advice, indicators, background_path, chapter):
    """
    Analiza un CV descriptivo y genera un reporte PDF con fondo, usando Gemini para indicadores.
    """
    # ... (c√≥digo existente para extracci√≥n de texto, carga de datos, etc. - SE MANTIENE IGUAL) ...

    position_advice = advice.get(position, {}) # Cargar advice para el cargo

    # REEMPLAZAR LA LLAMADA A calculate_indicators_for_report (o calculate_all_indicators)
    # indicator_results = calculate_indicators_for_report(...) # Funci√≥n anterior (keyword-based)
    indicator_results = calculate_indicators_for_report_gemini(lines, position, position_advice) # Usar funci√≥n Gemini para indicadores


    # ... (resto del c√≥digo de generaci√≥n del reporte -  TABLAS, P√ÅRRAFOS, ESTILOS, ETC. - SE MANTIENE IGUAL) ...
    # ... (Aseg√∫rate de INTEGRAR la tabla de PRESENTACI√ìN basada en Gemini como en la respuesta anterior) ...

    # Evaluaci√≥n de la PRESENTACI√ìN usando Gemini (INTEGRAR C√ìDIGO DE RESPUESTA ANTERIOR aqu√≠ si a√∫n no lo has hecho)
    resume_text = "" # Inicializar variable para el texto de la hoja de vida para la evaluaci√≥n de presentaci√≥n
    text_data = extract_text_with_headers_and_details(pdf_path) # Extraer texto con encabezados y detalles
    if text_data: # Si se extrajo texto con encabezados y detalles (para descriptive version)
        resume_text = " ".join([" ".join(details) for details in text_data.values()]) # Unir todos los detalles para la evaluaci√≥n de presentaci√≥n
    else: # Si no se pudo extraer con encabezados y detalles (fallback - usar extracci√≥n OCR general)
        resume_text= evaluate_cv_presentation(pdf_path) # Usar texto OCR general como fallback
        if not resume_text:
            return None, "No se pudo extraer el texto de la hoja de vida para la evaluaci√≥n de presentaci√≥n."

    presentation_scores = evaluate_presentation_gemini(resume_text, position) # Llama a Gemini para evaluar la presentaci√≥n

    if not presentation_scores: # Manejar el caso de error en la llamada a Gemini
        clarity_score = 0  # Puntajes por defecto si falla la API de Gemini
        professionalism_score = 0
        impact_score = 0
        round_overall_score = 0 # Usar round_overall_score para consistencia en la funci√≥n
    else:
        clarity_score = presentation_scores.get("clarity_score", 0)
        professionalism_score = presentation_scores.get("professionalism_score", 0)
        impact_score = presentation_scores.get("impact_score", 0)
        round_overall_score = presentation_scores.get("overall_presentation_score", 0) # Usar round_overall_score para consistencia

    # A√±adir resultados al reporte (TABLA DE PRESENTACI√ìN ADAPTADA - COPIA EL C√ìDIGO DE LA RESPUESTA ANTERIOR AQU√ç)
    elements.append(Paragraph("<b>Evaluaci√≥n de la Presentaci√≥n:</b>", styles['CenturyGothicBold']))
    elements.append(Spacer(1, 0.2 * inch))
    presentation_table = Table(
        [
            ["Criterio", "Puntaje (Escala 1-5)"],
            ["Claridad y Concisi√≥n", f"{clarity_score:.2f}"],
            ["Profesionalismo", f"{professionalism_score:.2f}"],
            ["Impacto y Persuasi√≥n", f"{impact_score:.2f}"],
            ["Puntaje Total de Presentaci√≥n", f"{round_overall_score:.2f}"]
        ],
        colWidths=[4 * inch, 2 * inch]
    )
    presentation_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor("#F0F0F0")),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
        ('FONTNAME', (0, 0), (-1, 0), 'CenturyGothicBold'),
        ('FONTNAME', (0, 1), (-1, -1), 'CenturyGothic'),
        ('FONTSIZE', (0, 0), (-1, -1), 10),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 8),
        ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),
        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
    ]))
    elements.append(presentation_table)
    elements.append(Spacer(1, 0.2 * inch))


    # Construcci√≥n del PDF (se mantiene igual)
    doc.build(elements, onFirstPage=on_first_page, onLaterPages=on_later_pages)
    # Read the PDF file as bytes and Encode to base64 (se mantiene igual)
    with open(output_path, "rb") as pdf_file:
        pdf_bytes = pdf_file.read()
    pdf_base64_string = base64.b64encode(pdf_bytes).decode('utf-8')
    return pdf_base64_string, output_path
```
